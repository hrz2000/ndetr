{"train/det_cls.d0_loss": 2.401322841644287, "train/det_cls.d1_loss": 2.388082981109619, "train/det_cls.d2_loss": 2.460132360458374, "train/det_cls.d3_loss": 2.4196643829345703, "train/det_cls.d4_loss": 2.525692939758301, "train/det_cls.d5_loss": 2.471968173980713, "train/det_reg.d0_loss": 3.8163058757781982, "train/det_reg.d1_loss": 3.8995954990386963, "train/det_reg.d2_loss": 4.160523891448975, "train/det_reg.d3_loss": 4.272912502288818, "train/det_reg.d4_loss": 4.489224433898926, "train/det_reg.d5_loss": 4.771045207977295, "train/wp.d0_loss": 2.4189724922180176, "train/wp.d1_loss": 2.401447296142578, "train/wp.d2_loss": 2.3686742782592773, "train/wp.d3_loss": 2.417538642883301, "train/wp.d4_loss": 2.282291889190674, "train/wp.d5_loss": 2.209127426147461, "train/wp": 2.209127426147461, "train/attnmap_loss": 1.4588326215744019, "train/loss": 55.633358001708984, "train/grad_norm": 67.6231460571289, "learning_rate": 6.666666666666666e-05, "momentum": 0.9, "_runtime": 32.60096788406372, "_timestamp": 1676689896.2924314, "_step": 1}
{"train/det_cls.d0_loss": 2.297689199447632, "train/det_cls.d1_loss": 2.2702879905700684, "train/det_cls.d2_loss": 2.2937519550323486, "train/det_cls.d3_loss": 2.1873598098754883, "train/det_cls.d4_loss": 2.3437352180480957, "train/det_cls.d5_loss": 2.292616605758667, "train/det_reg.d0_loss": 3.7070248126983643, "train/det_reg.d1_loss": 3.7837769985198975, "train/det_reg.d2_loss": 3.96604061126709, "train/det_reg.d3_loss": 4.0786333084106445, "train/det_reg.d4_loss": 4.168212890625, "train/det_reg.d5_loss": 4.314334869384766, "train/wp.d0_loss": 1.986790657043457, "train/wp.d1_loss": 1.8951083421707153, "train/wp.d2_loss": 1.8574700355529785, "train/wp.d3_loss": 1.8071634769439697, "train/wp.d4_loss": 1.715210199356079, "train/wp.d5_loss": 1.6039299964904785, "train/wp": 1.6039299964904785, "train/attnmap_loss": 1.5532808303833008, "train/loss": 50.12241744995117, "train/grad_norm": 57.593074798583984, "learning_rate": 6.693333333333331e-05, "momentum": 0.9, "_runtime": 39.14003586769104, "_timestamp": 1676689902.8314993, "_step": 2}
{"train/det_cls.d0_loss": 2.131211757659912, "train/det_cls.d1_loss": 2.161865472793579, "train/det_cls.d2_loss": 2.164473056793213, "train/det_cls.d3_loss": 2.052140712738037, "train/det_cls.d4_loss": 2.1860287189483643, "train/det_cls.d5_loss": 2.113224983215332, "train/det_reg.d0_loss": 3.713306188583374, "train/det_reg.d1_loss": 3.756096601486206, "train/det_reg.d2_loss": 3.827214241027832, "train/det_reg.d3_loss": 3.806483507156372, "train/det_reg.d4_loss": 3.8126769065856934, "train/det_reg.d5_loss": 3.8456006050109863, "train/wp.d0_loss": 2.0755434036254883, "train/wp.d1_loss": 1.9182277917861938, "train/wp.d2_loss": 1.842698574066162, "train/wp.d3_loss": 1.7276339530944824, "train/wp.d4_loss": 1.6430577039718628, "train/wp.d5_loss": 1.5351996421813965, "train/wp": 1.5351996421813965, "train/attnmap_loss": 1.546109676361084, "train/loss": 47.85879135131836, "train/grad_norm": 51.23554992675781, "learning_rate": 6.72e-05, "momentum": 0.9, "_runtime": 42.21233820915222, "_timestamp": 1676689905.9038017, "_step": 3}
{"train/det_cls.d0_loss": 2.023402452468872, "train/det_cls.d1_loss": 2.039771318435669, "train/det_cls.d2_loss": 2.0381429195404053, "train/det_cls.d3_loss": 1.8907442092895508, "train/det_cls.d4_loss": 2.0239343643188477, "train/det_cls.d5_loss": 1.9579330682754517, "train/det_reg.d0_loss": 3.789116859436035, "train/det_reg.d1_loss": 3.8009033203125, "train/det_reg.d2_loss": 3.8714966773986816, "train/det_reg.d3_loss": 3.7793402671813965, "train/det_reg.d4_loss": 3.721756935119629, "train/det_reg.d5_loss": 3.670973300933838, "train/wp.d0_loss": 2.1618010997772217, "train/wp.d1_loss": 1.9316067695617676, "train/wp.d2_loss": 1.828782081604004, "train/wp.d3_loss": 1.696209192276001, "train/wp.d4_loss": 1.6019647121429443, "train/wp.d5_loss": 1.5248661041259766, "train/wp": 1.5248661041259766, "train/attnmap_loss": 1.7710411548614502, "train/loss": 47.12378692626953, "train/grad_norm": 56.9536018371582, "learning_rate": 6.746666666666666e-05, "momentum": 0.9, "_runtime": 45.28634595870972, "_timestamp": 1676689908.9778094, "_step": 4}
{"train/det_cls.d0_loss": 1.8931843042373657, "train/det_cls.d1_loss": 1.9437695741653442, "train/det_cls.d2_loss": 1.9170950651168823, "train/det_cls.d3_loss": 1.7515945434570312, "train/det_cls.d4_loss": 1.9025520086288452, "train/det_cls.d5_loss": 1.7726118564605713, "train/det_reg.d0_loss": 3.6074631214141846, "train/det_reg.d1_loss": 3.5155153274536133, "train/det_reg.d2_loss": 3.5029823780059814, "train/det_reg.d3_loss": 3.4122281074523926, "train/det_reg.d4_loss": 3.3407652378082275, "train/det_reg.d5_loss": 3.3030004501342773, "train/wp.d0_loss": 1.878370761871338, "train/wp.d1_loss": 1.628280758857727, "train/wp.d2_loss": 1.5423051118850708, "train/wp.d3_loss": 1.427362322807312, "train/wp.d4_loss": 1.3751095533370972, "train/wp.d5_loss": 1.3039721250534058, "train/wp": 1.3039721250534058, "train/attnmap_loss": 1.407943844795227, "train/loss": 42.42610549926758, "train/grad_norm": 39.983211517333984, "learning_rate": 6.773333333333332e-05, "momentum": 0.9, "_runtime": 48.662150621414185, "_timestamp": 1676689912.353614, "_step": 5}
{"train/det_cls.d0_loss": 1.8132132291793823, "train/det_cls.d1_loss": 1.8527840375900269, "train/det_cls.d2_loss": 1.8209357261657715, "train/det_cls.d3_loss": 1.6520895957946777, "train/det_cls.d4_loss": 1.7961366176605225, "train/det_cls.d5_loss": 1.6456621885299683, "train/det_reg.d0_loss": 3.6355414390563965, "train/det_reg.d1_loss": 3.5070338249206543, "train/det_reg.d2_loss": 3.4440133571624756, "train/det_reg.d3_loss": 3.3395678997039795, "train/det_reg.d4_loss": 3.2852871417999268, "train/det_reg.d5_loss": 3.2821903228759766, "train/wp.d0_loss": 1.8787767887115479, "train/wp.d1_loss": 1.6251561641693115, "train/wp.d2_loss": 1.5470858812332153, "train/wp.d3_loss": 1.384761095046997, "train/wp.d4_loss": 1.3714958429336548, "train/wp.d5_loss": 1.2660292387008667, "train/wp": 1.2660292387008667, "train/attnmap_loss": 1.3570207357406616, "train/loss": 41.504783630371094, "train/grad_norm": 45.221519470214844, "learning_rate": 6.8e-05, "momentum": 0.9, "_runtime": 51.99303913116455, "_timestamp": 1676689915.6845026, "_step": 6}
{"train/det_cls.d0_loss": 1.7110718488693237, "train/det_cls.d1_loss": 1.7609950304031372, "train/det_cls.d2_loss": 1.6679476499557495, "train/det_cls.d3_loss": 1.5733048915863037, "train/det_cls.d4_loss": 1.58207368850708, "train/det_cls.d5_loss": 1.4805859327316284, "train/det_reg.d0_loss": 3.5133161544799805, "train/det_reg.d1_loss": 3.4462332725524902, "train/det_reg.d2_loss": 3.380279064178467, "train/det_reg.d3_loss": 3.350008487701416, "train/det_reg.d4_loss": 3.378009080886841, "train/det_reg.d5_loss": 3.3999760150909424, "train/wp.d0_loss": 1.7413721084594727, "train/wp.d1_loss": 1.4621427059173584, "train/wp.d2_loss": 1.3967708349227905, "train/wp.d3_loss": 1.2845487594604492, "train/wp.d4_loss": 1.2833200693130493, "train/wp.d5_loss": 1.1921143531799316, "train/wp": 1.1921143531799316, "train/attnmap_loss": 1.3624992370605469, "train/loss": 39.96656799316406, "train/grad_norm": 46.20243835449219, "learning_rate": 6.826666666666665e-05, "momentum": 0.9, "_runtime": 54.96520757675171, "_timestamp": 1676689918.656671, "_step": 7}
{"train/det_cls.d0_loss": 1.6623183488845825, "train/det_cls.d1_loss": 1.682446837425232, "train/det_cls.d2_loss": 1.6705479621887207, "train/det_cls.d3_loss": 1.4707393646240234, "train/det_cls.d4_loss": 1.5592081546783447, "train/det_cls.d5_loss": 1.3885923624038696, "train/det_reg.d0_loss": 3.4040980339050293, "train/det_reg.d1_loss": 3.2892110347747803, "train/det_reg.d2_loss": 3.168078660964966, "train/det_reg.d3_loss": 3.2583045959472656, "train/det_reg.d4_loss": 3.3768577575683594, "train/det_reg.d5_loss": 3.3651771545410156, "train/wp.d0_loss": 1.5775690078735352, "train/wp.d1_loss": 1.3792760372161865, "train/wp.d2_loss": 1.3285484313964844, "train/wp.d3_loss": 1.2677671909332275, "train/wp.d4_loss": 1.2348583936691284, "train/wp.d5_loss": 1.1924158334732056, "train/wp": 1.1924158334732056, "train/attnmap_loss": 2.2733066082000732, "train/loss": 39.54932403564453, "train/grad_norm": 38.68752670288086, "learning_rate": 6.853333333333331e-05, "momentum": 0.9, "_runtime": 58.25188589096069, "_timestamp": 1676689921.9433494, "_step": 8}
{"train/det_cls.d0_loss": 1.562894582748413, "train/det_cls.d1_loss": 1.584304690361023, "train/det_cls.d2_loss": 1.5094499588012695, "train/det_cls.d3_loss": 1.3556604385375977, "train/det_cls.d4_loss": 1.3775948286056519, "train/det_cls.d5_loss": 1.2369438409805298, "train/det_reg.d0_loss": 3.5327329635620117, "train/det_reg.d1_loss": 3.3352367877960205, "train/det_reg.d2_loss": 3.2696526050567627, "train/det_reg.d3_loss": 3.336766481399536, "train/det_reg.d4_loss": 3.356250286102295, "train/det_reg.d5_loss": 3.312903881072998, "train/wp.d0_loss": 1.540226697921753, "train/wp.d1_loss": 1.2928508520126343, "train/wp.d2_loss": 1.2253378629684448, "train/wp.d3_loss": 1.153099775314331, "train/wp.d4_loss": 1.1093727350234985, "train/wp.d5_loss": 1.0875756740570068, "train/wp": 1.0875756740570068, "train/attnmap_loss": 1.2072463035583496, "train/loss": 37.38610076904297, "train/grad_norm": 33.22376251220703, "learning_rate": 6.879999999999999e-05, "momentum": 0.9, "_runtime": 61.69839668273926, "_timestamp": 1676689925.3898602, "_step": 9}
{"train/det_cls.d0_loss": 1.4315739870071411, "train/det_cls.d1_loss": 1.4609816074371338, "train/det_cls.d2_loss": 1.3587647676467896, "train/det_cls.d3_loss": 1.2069971561431885, "train/det_cls.d4_loss": 1.2379659414291382, "train/det_cls.d5_loss": 1.1340594291687012, "train/det_reg.d0_loss": 3.4031455516815186, "train/det_reg.d1_loss": 3.265994071960449, "train/det_reg.d2_loss": 3.1852939128875732, "train/det_reg.d3_loss": 3.2670681476593018, "train/det_reg.d4_loss": 3.193331241607666, "train/det_reg.d5_loss": 3.1318864822387695, "train/wp.d0_loss": 1.5731661319732666, "train/wp.d1_loss": 1.2275917530059814, "train/wp.d2_loss": 1.145448088645935, "train/wp.d3_loss": 1.0365275144577026, "train/wp.d4_loss": 0.9929183125495911, "train/wp.d5_loss": 0.9956241846084595, "train/wp": 0.9956241846084595, "train/attnmap_loss": 2.027493476867676, "train/loss": 36.27583312988281, "train/grad_norm": 37.34763717651367, "learning_rate": 6.906666666666666e-05, "momentum": 0.9, "_runtime": 65.08517360687256, "_timestamp": 1676689928.776637, "_step": 10}
{"train/det_cls.d0_loss": 1.345858097076416, "train/det_cls.d1_loss": 1.35623037815094, "train/det_cls.d2_loss": 1.2448831796646118, "train/det_cls.d3_loss": 1.093229055404663, "train/det_cls.d4_loss": 1.1086397171020508, "train/det_cls.d5_loss": 1.0371432304382324, "train/det_reg.d0_loss": 3.4915411472320557, "train/det_reg.d1_loss": 3.312364101409912, "train/det_reg.d2_loss": 3.2066502571105957, "train/det_reg.d3_loss": 3.237366199493408, "train/det_reg.d4_loss": 3.196993350982666, "train/det_reg.d5_loss": 3.1834158897399902, "train/wp.d0_loss": 1.387074589729309, "train/wp.d1_loss": 1.1237680912017822, "train/wp.d2_loss": 1.0689189434051514, "train/wp.d3_loss": 1.0319279432296753, "train/wp.d4_loss": 1.0127387046813965, "train/wp.d5_loss": 1.0137193202972412, "train/wp": 1.0137193202972412, "train/attnmap_loss": 1.6571757793426514, "train/loss": 35.10963821411133, "train/grad_norm": 31.07913589477539, "learning_rate": 6.933333333333332e-05, "momentum": 0.9, "_runtime": 68.11126518249512, "_timestamp": 1676689931.8027287, "_step": 11}
{"train/det_cls.d0_loss": 1.2917263507843018, "train/det_cls.d1_loss": 1.2898834943771362, "train/det_cls.d2_loss": 1.124600887298584, "train/det_cls.d3_loss": 1.014710783958435, "train/det_cls.d4_loss": 1.0093165636062622, "train/det_cls.d5_loss": 0.9752618074417114, "train/det_reg.d0_loss": 3.5235002040863037, "train/det_reg.d1_loss": 3.3758625984191895, "train/det_reg.d2_loss": 3.3611209392547607, "train/det_reg.d3_loss": 3.3887064456939697, "train/det_reg.d4_loss": 3.41778564453125, "train/det_reg.d5_loss": 3.4864606857299805, "train/wp.d0_loss": 1.3574814796447754, "train/wp.d1_loss": 1.1024649143218994, "train/wp.d2_loss": 1.0714375972747803, "train/wp.d3_loss": 1.0823835134506226, "train/wp.d4_loss": 1.0686688423156738, "train/wp.d5_loss": 1.0592598915100098, "train/wp": 1.0592598915100098, "train/attnmap_loss": 1.7881191968917847, "train/loss": 35.78874969482422, "train/grad_norm": 31.837072372436523, "learning_rate": 6.96e-05, "momentum": 0.9, "_runtime": 71.44827151298523, "_timestamp": 1676689935.139735, "_step": 12}
{"train/det_cls.d0_loss": 1.2168141603469849, "train/det_cls.d1_loss": 1.1962045431137085, "train/det_cls.d2_loss": 1.0485286712646484, "train/det_cls.d3_loss": 0.9162256717681885, "train/det_cls.d4_loss": 0.9586913585662842, "train/det_cls.d5_loss": 0.9058335423469543, "train/det_reg.d0_loss": 3.346367835998535, "train/det_reg.d1_loss": 3.2153234481811523, "train/det_reg.d2_loss": 3.1756248474121094, "train/det_reg.d3_loss": 3.186876058578491, "train/det_reg.d4_loss": 3.2397420406341553, "train/det_reg.d5_loss": 3.311650276184082, "train/wp.d0_loss": 1.390970230102539, "train/wp.d1_loss": 1.1395370960235596, "train/wp.d2_loss": 1.1013669967651367, "train/wp.d3_loss": 1.073575496673584, "train/wp.d4_loss": 1.0712350606918335, "train/wp.d5_loss": 1.0595207214355469, "train/wp": 1.0595207214355469, "train/attnmap_loss": 1.484656572341919, "train/loss": 34.03874588012695, "train/grad_norm": 28.43857192993164, "learning_rate": 6.986666666666665e-05, "momentum": 0.9, "_runtime": 74.87932062149048, "_timestamp": 1676689938.570784, "_step": 13}
{"train/det_cls.d0_loss": 1.1806259155273438, "train/det_cls.d1_loss": 1.137349247932434, "train/det_cls.d2_loss": 0.9714285135269165, "train/det_cls.d3_loss": 0.8609212636947632, "train/det_cls.d4_loss": 0.8943803310394287, "train/det_cls.d5_loss": 0.8662724494934082, "train/det_reg.d0_loss": 3.347324848175049, "train/det_reg.d1_loss": 3.204660654067993, "train/det_reg.d2_loss": 3.244882583618164, "train/det_reg.d3_loss": 3.276998996734619, "train/det_reg.d4_loss": 3.287716865539551, "train/det_reg.d5_loss": 3.3090765476226807, "train/wp.d0_loss": 1.2925755977630615, "train/wp.d1_loss": 1.0143839120864868, "train/wp.d2_loss": 0.9944952726364136, "train/wp.d3_loss": 1.018317699432373, "train/wp.d4_loss": 1.0090843439102173, "train/wp.d5_loss": 0.9853249192237854, "train/wp": 0.9853249192237854, "train/attnmap_loss": 1.5175806283950806, "train/loss": 33.41340255737305, "train/grad_norm": 26.445940017700195, "learning_rate": 7.013333333333332e-05, "momentum": 0.9, "_runtime": 78.14782238006592, "_timestamp": 1676689941.8392859, "_step": 14}
{"train/det_cls.d0_loss": 1.1201053857803345, "train/det_cls.d1_loss": 1.063694715499878, "train/det_cls.d2_loss": 0.9112063646316528, "train/det_cls.d3_loss": 0.8018010854721069, "train/det_cls.d4_loss": 0.8515166640281677, "train/det_cls.d5_loss": 0.8209649324417114, "train/det_reg.d0_loss": 3.1985268592834473, "train/det_reg.d1_loss": 3.0873422622680664, "train/det_reg.d2_loss": 3.135509729385376, "train/det_reg.d3_loss": 3.159193515777588, "train/det_reg.d4_loss": 3.190380096435547, "train/det_reg.d5_loss": 3.241428852081299, "train/wp.d0_loss": 1.3081035614013672, "train/wp.d1_loss": 1.1167973279953003, "train/wp.d2_loss": 1.114625334739685, "train/wp.d3_loss": 1.156644582748413, "train/wp.d4_loss": 1.1404578685760498, "train/wp.d5_loss": 1.1235699653625488, "train/wp": 1.1235699653625488, "train/attnmap_loss": 2.27169132232666, "train/loss": 33.813560485839844, "train/grad_norm": 27.908470153808594, "learning_rate": 7.04e-05, "momentum": 0.9, "_runtime": 81.18837833404541, "_timestamp": 1676689944.8798418, "_step": 15}
{"train/det_cls.d0_loss": 1.0296611785888672, "train/det_cls.d1_loss": 0.9651538133621216, "train/det_cls.d2_loss": 0.8148330450057983, "train/det_cls.d3_loss": 0.7418551445007324, "train/det_cls.d4_loss": 0.775497317314148, "train/det_cls.d5_loss": 0.7719324827194214, "train/det_reg.d0_loss": 3.2289490699768066, "train/det_reg.d1_loss": 3.111588716506958, "train/det_reg.d2_loss": 3.1367032527923584, "train/det_reg.d3_loss": 3.1811280250549316, "train/det_reg.d4_loss": 3.2531909942626953, "train/det_reg.d5_loss": 3.20263671875, "train/wp.d0_loss": 1.3055208921432495, "train/wp.d1_loss": 1.1100735664367676, "train/wp.d2_loss": 1.0879331827163696, "train/wp.d3_loss": 1.114827036857605, "train/wp.d4_loss": 1.072951078414917, "train/wp.d5_loss": 1.0888497829437256, "train/wp": 1.0888497829437256, "train/attnmap_loss": 1.4481152296066284, "train/loss": 32.441402435302734, "train/grad_norm": 24.24657440185547, "learning_rate": 7.066666666666666e-05, "momentum": 0.9, "_runtime": 84.62475395202637, "_timestamp": 1676689948.3162174, "_step": 16}
{"train/det_cls.d0_loss": 0.9826673269271851, "train/det_cls.d1_loss": 0.9105480909347534, "train/det_cls.d2_loss": 0.777906060218811, "train/det_cls.d3_loss": 0.6999210119247437, "train/det_cls.d4_loss": 0.7589101791381836, "train/det_cls.d5_loss": 0.7292165756225586, "train/det_reg.d0_loss": 3.1903679370880127, "train/det_reg.d1_loss": 3.0685505867004395, "train/det_reg.d2_loss": 3.133873224258423, "train/det_reg.d3_loss": 3.1962075233459473, "train/det_reg.d4_loss": 3.1692957878112793, "train/det_reg.d5_loss": 3.1443347930908203, "train/wp.d0_loss": 1.1778311729431152, "train/wp.d1_loss": 1.0982580184936523, "train/wp.d2_loss": 1.1021804809570312, "train/wp.d3_loss": 1.1608967781066895, "train/wp.d4_loss": 1.1110506057739258, "train/wp.d5_loss": 1.0926309823989868, "train/wp": 1.0926309823989868, "train/attnmap_loss": 1.5270094871520996, "train/loss": 32.031654357910156, "train/grad_norm": 25.92500114440918, "learning_rate": 7.093333333333331e-05, "momentum": 0.9, "_runtime": 88.0660650730133, "_timestamp": 1676689951.7575285, "_step": 17}
