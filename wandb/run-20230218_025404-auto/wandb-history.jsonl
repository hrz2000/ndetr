{"_runtime":143,"_step":33}
{"train/det_cls.d0_loss": 0.5810781717300415, "train/det_cls.d1_loss": 0.6143587827682495, "train/det_cls.d2_loss": 0.6104224324226379, "train/det_cls.d3_loss": 0.6100069284439087, "train/det_cls.d4_loss": 0.618456244468689, "train/det_cls.d5_loss": 0.6304281949996948, "train/det_reg.d0_loss": 2.7096164226531982, "train/det_reg.d1_loss": 2.568460464477539, "train/det_reg.d2_loss": 2.565260887145996, "train/det_reg.d3_loss": 2.5199480056762695, "train/det_reg.d4_loss": 2.4845986366271973, "train/det_reg.d5_loss": 2.433835029602051, "train/wp.d0_loss": 0.9792214632034302, "train/wp.d1_loss": 0.8607040643692017, "train/wp.d2_loss": 0.86064213514328, "train/wp.d3_loss": 0.8655446767807007, "train/wp.d4_loss": 0.8641691207885742, "train/wp.d5_loss": 0.85987788438797, "train/wp": 0.85987788438797, "train/attnmap_loss": 1.7637572288513184, "train/loss": 26.00038719177246, "train/grad_norm": 18.172706604003906, "learning_rate": 7.546666666666667e-05, "momentum": 0.9, "_runtime": 280.15751791000366, "_timestamp": 1676688961.5608532, "_step": 34}
{"train/det_cls.d0_loss": 0.5639300346374512, "train/det_cls.d1_loss": 0.5948253273963928, "train/det_cls.d2_loss": 0.5891139507293701, "train/det_cls.d3_loss": 0.5887842178344727, "train/det_cls.d4_loss": 0.5964115262031555, "train/det_cls.d5_loss": 0.6074419021606445, "train/det_reg.d0_loss": 2.672017812728882, "train/det_reg.d1_loss": 2.4834017753601074, "train/det_reg.d2_loss": 2.4999570846557617, "train/det_reg.d3_loss": 2.4766037464141846, "train/det_reg.d4_loss": 2.4600839614868164, "train/det_reg.d5_loss": 2.456238269805908, "train/wp.d0_loss": 1.0253201723098755, "train/wp.d1_loss": 0.959577202796936, "train/wp.d2_loss": 0.9387378692626953, "train/wp.d3_loss": 0.949006974697113, "train/wp.d4_loss": 0.946851909160614, "train/wp.d5_loss": 0.9583262205123901, "train/wp": 0.9583262205123901, "train/attnmap_loss": 1.2974330186843872, "train/loss": 25.6640625, "train/grad_norm": 18.024221420288086, "learning_rate": 7.573333333333332e-05, "momentum": 0.9, "_runtime": 283.0561487674713, "_timestamp": 1676688964.459484, "_step": 35}
{"train/det_cls.d0_loss": 0.5637565851211548, "train/det_cls.d1_loss": 0.5927773714065552, "train/det_cls.d2_loss": 0.5856974720954895, "train/det_cls.d3_loss": 0.5837910771369934, "train/det_cls.d4_loss": 0.5940887331962585, "train/det_cls.d5_loss": 0.6060147285461426, "train/det_reg.d0_loss": 2.614443778991699, "train/det_reg.d1_loss": 2.4523208141326904, "train/det_reg.d2_loss": 2.454575538635254, "train/det_reg.d3_loss": 2.4788103103637695, "train/det_reg.d4_loss": 2.473433017730713, "train/det_reg.d5_loss": 2.475023031234741, "train/wp.d0_loss": 1.0066311359405518, "train/wp.d1_loss": 0.9917546510696411, "train/wp.d2_loss": 0.9824149012565613, "train/wp.d3_loss": 0.9549299478530884, "train/wp.d4_loss": 0.9606289267539978, "train/wp.d5_loss": 0.9863671064376831, "train/wp": 0.9863671064376831, "train/attnmap_loss": 1.7789785861968994, "train/loss": 26.136436462402344, "train/grad_norm": 16.05596923828125, "learning_rate": 7.6e-05, "momentum": 0.9, "_runtime": 285.9544334411621, "_timestamp": 1676688967.3577688, "_step": 36}
{"train/det_cls.d0_loss": 0.5723131895065308, "train/det_cls.d1_loss": 0.6048992872238159, "train/det_cls.d2_loss": 0.5994607210159302, "train/det_cls.d3_loss": 0.5941356420516968, "train/det_cls.d4_loss": 0.6037166118621826, "train/det_cls.d5_loss": 0.6144087314605713, "train/det_reg.d0_loss": 2.6409945487976074, "train/det_reg.d1_loss": 2.485295295715332, "train/det_reg.d2_loss": 2.4865310192108154, "train/det_reg.d3_loss": 2.4767959117889404, "train/det_reg.d4_loss": 2.480602741241455, "train/det_reg.d5_loss": 2.5087575912475586, "train/wp.d0_loss": 0.9954628944396973, "train/wp.d1_loss": 0.9695771932601929, "train/wp.d2_loss": 0.9578602910041809, "train/wp.d3_loss": 0.9376647472381592, "train/wp.d4_loss": 0.9272820353507996, "train/wp.d5_loss": 0.9472581744194031, "train/wp": 0.9472581744194031, "train/attnmap_loss": 1.4997198581695557, "train/loss": 25.902734756469727, "train/grad_norm": 19.092586517333984, "learning_rate": 7.626666666666665e-05, "momentum": 0.9, "_runtime": 289.20929741859436, "_timestamp": 1676688970.6126328, "_step": 37}
{"train/det_cls.d0_loss": 0.567965030670166, "train/det_cls.d1_loss": 0.5966342091560364, "train/det_cls.d2_loss": 0.5892017483711243, "train/det_cls.d3_loss": 0.5841600894927979, "train/det_cls.d4_loss": 0.5968388915061951, "train/det_cls.d5_loss": 0.6084341406822205, "train/det_reg.d0_loss": 2.6136763095855713, "train/det_reg.d1_loss": 2.463322162628174, "train/det_reg.d2_loss": 2.4794270992279053, "train/det_reg.d3_loss": 2.463409423828125, "train/det_reg.d4_loss": 2.4572906494140625, "train/det_reg.d5_loss": 2.5294570922851562, "train/wp.d0_loss": 0.9624226689338684, "train/wp.d1_loss": 0.9315957427024841, "train/wp.d2_loss": 0.9166896939277649, "train/wp.d3_loss": 0.9104687571525574, "train/wp.d4_loss": 0.8971681594848633, "train/wp.d5_loss": 0.90348219871521, "train/wp": 0.90348219871521, "train/attnmap_loss": 1.6098357439041138, "train/loss": 25.68147850036621, "train/grad_norm": 13.889410018920898, "learning_rate": 7.653333333333333e-05, "momentum": 0.9, "_runtime": 292.4708340167999, "_timestamp": 1676688973.8741693, "_step": 38}
{"train/det_cls.d0_loss": 0.5680665373802185, "train/det_cls.d1_loss": 0.5973701477050781, "train/det_cls.d2_loss": 0.6014188528060913, "train/det_cls.d3_loss": 0.5895090699195862, "train/det_cls.d4_loss": 0.6002835035324097, "train/det_cls.d5_loss": 0.6138162016868591, "train/det_reg.d0_loss": 2.60837721824646, "train/det_reg.d1_loss": 2.4781742095947266, "train/det_reg.d2_loss": 2.4998998641967773, "train/det_reg.d3_loss": 2.505422592163086, "train/det_reg.d4_loss": 2.514655828475952, "train/det_reg.d5_loss": 2.531782388687134, "train/wp.d0_loss": 1.0396004915237427, "train/wp.d1_loss": 0.9953650236129761, "train/wp.d2_loss": 0.9893914461135864, "train/wp.d3_loss": 0.9855514168739319, "train/wp.d4_loss": 0.9854799509048462, "train/wp.d5_loss": 0.9815585613250732, "train/wp": 0.9815585613250732, "train/attnmap_loss": 1.270795226097107, "train/loss": 25.95651626586914, "train/grad_norm": 16.56035041809082, "learning_rate": 7.679999999999998e-05, "momentum": 0.9, "_runtime": 295.4518344402313, "_timestamp": 1676688976.8551698, "_step": 39}
{"train/det_cls.d0_loss": 0.559967577457428, "train/det_cls.d1_loss": 0.5817940831184387, "train/det_cls.d2_loss": 0.5773924589157104, "train/det_cls.d3_loss": 0.5759931802749634, "train/det_cls.d4_loss": 0.5862630605697632, "train/det_cls.d5_loss": 0.5931649804115295, "train/det_reg.d0_loss": 2.629376173019409, "train/det_reg.d1_loss": 2.480896234512329, "train/det_reg.d2_loss": 2.519111394882202, "train/det_reg.d3_loss": 2.526277780532837, "train/det_reg.d4_loss": 2.5356178283691406, "train/det_reg.d5_loss": 2.5202221870422363, "train/wp.d0_loss": 1.019892692565918, "train/wp.d1_loss": 1.0018236637115479, "train/wp.d2_loss": 0.9854317903518677, "train/wp.d3_loss": 0.9700311422348022, "train/wp.d4_loss": 0.967644989490509, "train/wp.d5_loss": 0.9756600856781006, "train/wp": 0.9756600856781006, "train/attnmap_loss": 1.784714698791504, "train/loss": 26.391277313232422, "train/grad_norm": 18.61486053466797, "learning_rate": 7.706666666666664e-05, "momentum": 0.9, "_runtime": 298.273766040802, "_timestamp": 1676688979.6771014, "_step": 40}
{"train/det_cls.d0_loss": 0.5600336790084839, "train/det_cls.d1_loss": 0.5860785841941833, "train/det_cls.d2_loss": 0.5885301232337952, "train/det_cls.d3_loss": 0.5805684328079224, "train/det_cls.d4_loss": 0.5959938168525696, "train/det_cls.d5_loss": 0.604800283908844, "train/det_reg.d0_loss": 2.6861283779144287, "train/det_reg.d1_loss": 2.547699213027954, "train/det_reg.d2_loss": 2.5831847190856934, "train/det_reg.d3_loss": 2.6247522830963135, "train/det_reg.d4_loss": 2.6167073249816895, "train/det_reg.d5_loss": 2.610680103302002, "train/wp.d0_loss": 1.0867526531219482, "train/wp.d1_loss": 1.0679113864898682, "train/wp.d2_loss": 1.0455225706100464, "train/wp.d3_loss": 1.066393256187439, "train/wp.d4_loss": 1.0589648485183716, "train/wp.d5_loss": 1.0421929359436035, "train/wp": 1.0421929359436035, "train/attnmap_loss": 1.4620370864868164, "train/loss": 27.014930725097656, "train/grad_norm": 19.025033950805664, "learning_rate": 7.733333333333332e-05, "momentum": 0.9, "_runtime": 301.618136882782, "_timestamp": 1676688983.0214722, "_step": 41}
{"train/det_cls.d0_loss": 0.5586747527122498, "train/det_cls.d1_loss": 0.5813270211219788, "train/det_cls.d2_loss": 0.5730774402618408, "train/det_cls.d3_loss": 0.5750905871391296, "train/det_cls.d4_loss": 0.5866254568099976, "train/det_cls.d5_loss": 0.5956684350967407, "train/det_reg.d0_loss": 2.5779623985290527, "train/det_reg.d1_loss": 2.4312901496887207, "train/det_reg.d2_loss": 2.511807680130005, "train/det_reg.d3_loss": 2.533771514892578, "train/det_reg.d4_loss": 2.5004849433898926, "train/det_reg.d5_loss": 2.5069851875305176, "train/wp.d0_loss": 1.0057110786437988, "train/wp.d1_loss": 1.0058836936950684, "train/wp.d2_loss": 0.9876243472099304, "train/wp.d3_loss": 0.9857981204986572, "train/wp.d4_loss": 0.9901659488677979, "train/wp.d5_loss": 0.9989237785339355, "train/wp": 0.9989237785339355, "train/attnmap_loss": 1.2768949270248413, "train/loss": 25.783767700195312, "train/grad_norm": 24.645538330078125, "learning_rate": 7.759999999999999e-05, "momentum": 0.9, "_runtime": 304.9013235569, "_timestamp": 1676688986.304659, "_step": 42}
{"train/det_cls.d0_loss": 0.5913851261138916, "train/det_cls.d1_loss": 0.6108690500259399, "train/det_cls.d2_loss": 0.6070360541343689, "train/det_cls.d3_loss": 0.606739342212677, "train/det_cls.d4_loss": 0.6285607814788818, "train/det_cls.d5_loss": 0.6259397268295288, "train/det_reg.d0_loss": 2.486431121826172, "train/det_reg.d1_loss": 2.360928773880005, "train/det_reg.d2_loss": 2.382202386856079, "train/det_reg.d3_loss": 2.4296531677246094, "train/det_reg.d4_loss": 2.473940372467041, "train/det_reg.d5_loss": 2.522488594055176, "train/wp.d0_loss": 0.953954815864563, "train/wp.d1_loss": 0.9282003045082092, "train/wp.d2_loss": 0.9126798510551453, "train/wp.d3_loss": 0.9166951179504395, "train/wp.d4_loss": 0.9189845323562622, "train/wp.d5_loss": 0.9136080741882324, "train/wp": 0.9136080741882324, "train/attnmap_loss": 1.3460800647735596, "train/loss": 25.21637725830078, "train/grad_norm": 19.908239364624023, "learning_rate": 7.786666666666664e-05, "momentum": 0.9, "_runtime": 307.8382019996643, "_timestamp": 1676688989.2415373, "_step": 43}
{"train/det_cls.d0_loss": 0.5707147717475891, "train/det_cls.d1_loss": 0.5976110100746155, "train/det_cls.d2_loss": 0.5921368598937988, "train/det_cls.d3_loss": 0.5983813405036926, "train/det_cls.d4_loss": 0.616546630859375, "train/det_cls.d5_loss": 0.6222745180130005, "train/det_reg.d0_loss": 2.531602621078491, "train/det_reg.d1_loss": 2.4202404022216797, "train/det_reg.d2_loss": 2.4718122482299805, "train/det_reg.d3_loss": 2.4877302646636963, "train/det_reg.d4_loss": 2.4603614807128906, "train/det_reg.d5_loss": 2.542701244354248, "train/wp.d0_loss": 1.0174288749694824, "train/wp.d1_loss": 1.0231760740280151, "train/wp.d2_loss": 0.988731324672699, "train/wp.d3_loss": 0.9905762672424316, "train/wp.d4_loss": 0.9911328554153442, "train/wp.d5_loss": 0.9908195734024048, "train/wp": 0.9908195734024048, "train/attnmap_loss": 1.8216289281845093, "train/loss": 26.33560562133789, "train/grad_norm": 26.203716278076172, "learning_rate": 7.813333333333333e-05, "momentum": 0.9, "_runtime": 310.67731857299805, "_timestamp": 1676688992.080654, "_step": 44}
{"train/det_cls.d0_loss": 0.5557527542114258, "train/det_cls.d1_loss": 0.5760946869850159, "train/det_cls.d2_loss": 0.5715421438217163, "train/det_cls.d3_loss": 0.5830927491188049, "train/det_cls.d4_loss": 0.6021133661270142, "train/det_cls.d5_loss": 0.6038305163383484, "train/det_reg.d0_loss": 2.4454054832458496, "train/det_reg.d1_loss": 2.3515191078186035, "train/det_reg.d2_loss": 2.394462823867798, "train/det_reg.d3_loss": 2.3761024475097656, "train/det_reg.d4_loss": 2.3671584129333496, "train/det_reg.d5_loss": 2.4514122009277344, "train/wp.d0_loss": 0.9315569996833801, "train/wp.d1_loss": 0.9133653044700623, "train/wp.d2_loss": 0.9191012978553772, "train/wp.d3_loss": 0.9378350973129272, "train/wp.d4_loss": 0.9308052062988281, "train/wp.d5_loss": 0.9235309362411499, "train/wp": 0.9235309362411499, "train/attnmap_loss": 1.5373955965042114, "train/loss": 24.972076416015625, "train/grad_norm": 31.685482025146484, "learning_rate": 7.839999999999998e-05, "momentum": 0.9, "_runtime": 313.92022013664246, "_timestamp": 1676688995.3235555, "_step": 45}
{"train/det_cls.d0_loss": 0.5547568798065186, "train/det_cls.d1_loss": 0.5778427720069885, "train/det_cls.d2_loss": 0.583214521408081, "train/det_cls.d3_loss": 0.585695743560791, "train/det_cls.d4_loss": 0.6016162633895874, "train/det_cls.d5_loss": 0.616028904914856, "train/det_reg.d0_loss": 2.5578222274780273, "train/det_reg.d1_loss": 2.4201807975769043, "train/det_reg.d2_loss": 2.494053602218628, "train/det_reg.d3_loss": 2.480604887008667, "train/det_reg.d4_loss": 2.4443256855010986, "train/det_reg.d5_loss": 2.4851346015930176, "train/wp.d0_loss": 1.0811293125152588, "train/wp.d1_loss": 1.0911046266555786, "train/wp.d2_loss": 1.066771388053894, "train/wp.d3_loss": 1.0629866123199463, "train/wp.d4_loss": 1.0622135400772095, "train/wp.d5_loss": 1.0704951286315918, "train/wp": 1.0704951286315918, "train/attnmap_loss": 1.5790045261383057, "train/loss": 26.414981842041016, "train/grad_norm": 17.659976959228516, "learning_rate": 7.866666666666665e-05, "momentum": 0.9, "_runtime": 317.25768756866455, "_timestamp": 1676688998.661023, "_step": 46}
{"train/det_cls.d0_loss": 0.5761197805404663, "train/det_cls.d1_loss": 0.5978846549987793, "train/det_cls.d2_loss": 0.5979741215705872, "train/det_cls.d3_loss": 0.6145211458206177, "train/det_cls.d4_loss": 0.6181283593177795, "train/det_cls.d5_loss": 0.6302996873855591, "train/det_reg.d0_loss": 2.495079278945923, "train/det_reg.d1_loss": 2.383800983428955, "train/det_reg.d2_loss": 2.4620606899261475, "train/det_reg.d3_loss": 2.3860983848571777, "train/det_reg.d4_loss": 2.460905075073242, "train/det_reg.d5_loss": 2.4944796562194824, "train/wp.d0_loss": 0.8947020769119263, "train/wp.d1_loss": 0.8634021282196045, "train/wp.d2_loss": 0.8855541944503784, "train/wp.d3_loss": 0.9018872976303101, "train/wp.d4_loss": 0.8853367567062378, "train/wp.d5_loss": 0.8936083316802979, "train/wp": 0.8936083316802979, "train/attnmap_loss": 1.7165591716766357, "train/loss": 25.358402252197266, "train/grad_norm": 27.773317337036133, "learning_rate": 7.893333333333333e-05, "momentum": 0.9, "_runtime": 320.1880362033844, "_timestamp": 1676689001.5913715, "_step": 47}
{"train/det_cls.d0_loss": 0.5528459548950195, "train/det_cls.d1_loss": 0.5773789882659912, "train/det_cls.d2_loss": 0.5767768025398254, "train/det_cls.d3_loss": 0.5951288938522339, "train/det_cls.d4_loss": 0.609091579914093, "train/det_cls.d5_loss": 0.619488000869751, "train/det_reg.d0_loss": 2.4868171215057373, "train/det_reg.d1_loss": 2.345515489578247, "train/det_reg.d2_loss": 2.3876547813415527, "train/det_reg.d3_loss": 2.367164373397827, "train/det_reg.d4_loss": 2.512040853500366, "train/det_reg.d5_loss": 2.6801791191101074, "train/wp.d0_loss": 0.9665627479553223, "train/wp.d1_loss": 0.9559546709060669, "train/wp.d2_loss": 0.9413684606552124, "train/wp.d3_loss": 0.9209272265434265, "train/wp.d4_loss": 0.938445508480072, "train/wp.d5_loss": 0.9273828268051147, "train/wp": 0.9273828268051147, "train/attnmap_loss": 1.4968066215515137, "train/loss": 25.457530975341797, "train/grad_norm": 27.067241668701172, "learning_rate": 7.919999999999999e-05, "momentum": 0.9, "_runtime": 323.0455346107483, "_timestamp": 1676689004.44887, "_step": 48}
{"train/det_cls.d0_loss": 0.5458729267120361, "train/det_cls.d1_loss": 0.5656515955924988, "train/det_cls.d2_loss": 0.5604026317596436, "train/det_cls.d3_loss": 0.5806166529655457, "train/det_cls.d4_loss": 0.5940558910369873, "train/det_cls.d5_loss": 0.6026718616485596, "train/det_reg.d0_loss": 2.466852903366089, "train/det_reg.d1_loss": 2.3345322608947754, "train/det_reg.d2_loss": 2.3479928970336914, "train/det_reg.d3_loss": 2.339827060699463, "train/det_reg.d4_loss": 2.496070384979248, "train/det_reg.d5_loss": 2.588594913482666, "train/wp.d0_loss": 0.9602829217910767, "train/wp.d1_loss": 0.9352525472640991, "train/wp.d2_loss": 0.9349629878997803, "train/wp.d3_loss": 0.9329090118408203, "train/wp.d4_loss": 0.9407193660736084, "train/wp.d5_loss": 0.9326779246330261, "train/wp": 0.9326779246330261, "train/attnmap_loss": 1.5352282524108887, "train/loss": 25.195175170898438, "train/grad_norm": 26.396806716918945, "learning_rate": 7.946666666666664e-05, "momentum": 0.9, "_runtime": 326.1806671619415, "_timestamp": 1676689007.5840025, "_step": 49}
{"train/det_cls.d0_loss": 0.5661071538925171, "train/det_cls.d1_loss": 0.5883095264434814, "train/det_cls.d2_loss": 0.5834060907363892, "train/det_cls.d3_loss": 0.6015152335166931, "train/det_cls.d4_loss": 0.6278195977210999, "train/det_cls.d5_loss": 0.6193702816963196, "train/det_reg.d0_loss": 2.435790538787842, "train/det_reg.d1_loss": 2.3224308490753174, "train/det_reg.d2_loss": 2.339298725128174, "train/det_reg.d3_loss": 2.354719638824463, "train/det_reg.d4_loss": 2.4871761798858643, "train/det_reg.d5_loss": 2.619935989379883, "train/wp.d0_loss": 1.0522973537445068, "train/wp.d1_loss": 1.046849250793457, "train/wp.d2_loss": 1.0408837795257568, "train/wp.d3_loss": 1.0404858589172363, "train/wp.d4_loss": 1.0465764999389648, "train/wp.d5_loss": 1.0459494590759277, "train/wp": 1.0459494590759277, "train/attnmap_loss": 1.884655237197876, "train/loss": 26.30357551574707, "train/grad_norm": 18.352062225341797, "learning_rate": 7.973333333333332e-05, "momentum": 0.9, "_runtime": 329.51448941230774, "_timestamp": 1676689010.9178247, "_step": 50}
{"train/det_cls.d0_loss": 0.5423584580421448, "train/det_cls.d1_loss": 0.5691772103309631, "train/det_cls.d2_loss": 0.5727245807647705, "train/det_cls.d3_loss": 0.5933034420013428, "train/det_cls.d4_loss": 0.6053409576416016, "train/det_cls.d5_loss": 0.5983554124832153, "train/det_reg.d0_loss": 2.445979118347168, "train/det_reg.d1_loss": 2.3442978858947754, "train/det_reg.d2_loss": 2.394867420196533, "train/det_reg.d3_loss": 2.4368059635162354, "train/det_reg.d4_loss": 2.4516026973724365, "train/det_reg.d5_loss": 2.4712865352630615, "train/wp.d0_loss": 1.0122286081314087, "train/wp.d1_loss": 1.0067921876907349, "train/wp.d2_loss": 0.9902428984642029, "train/wp.d3_loss": 0.9956152439117432, "train/wp.d4_loss": 0.9849716424942017, "train/wp.d5_loss": 0.9928165078163147, "train/wp": 0.9928165078163147, "train/attnmap_loss": 1.8739465475082397, "train/loss": 25.882713317871094, "train/grad_norm": 30.665987014770508, "learning_rate": 7.999999999999998e-05, "momentum": 0.9, "_runtime": 332.42155170440674, "_timestamp": 1676689013.824887, "_step": 51}
{"train/det_cls.d0_loss": 0.5526512861251831, "train/det_cls.d1_loss": 0.5720567107200623, "train/det_cls.d2_loss": 0.5758998394012451, "train/det_cls.d3_loss": 0.5958358645439148, "train/det_cls.d4_loss": 0.6078866720199585, "train/det_cls.d5_loss": 0.5994966626167297, "train/det_reg.d0_loss": 2.458620309829712, "train/det_reg.d1_loss": 2.3311593532562256, "train/det_reg.d2_loss": 2.3629415035247803, "train/det_reg.d3_loss": 2.391267776489258, "train/det_reg.d4_loss": 2.493786096572876, "train/det_reg.d5_loss": 2.5148427486419678, "train/wp.d0_loss": 0.8891977071762085, "train/wp.d1_loss": 0.8821141719818115, "train/wp.d2_loss": 0.8858555555343628, "train/wp.d3_loss": 0.8836780786514282, "train/wp.d4_loss": 0.8791503310203552, "train/wp.d5_loss": 0.8880245685577393, "train/wp": 0.8880245685577393, "train/attnmap_loss": 1.7762706279754639, "train/loss": 25.140735626220703, "train/grad_norm": 32.118324279785156, "learning_rate": 8.026666666666665e-05, "momentum": 0.9, "_runtime": 335.23766469955444, "_timestamp": 1676689016.641, "_step": 52}
{"train/det_cls.d0_loss": 0.5551512241363525, "train/det_cls.d1_loss": 0.5739452838897705, "train/det_cls.d2_loss": 0.5684269666671753, "train/det_cls.d3_loss": 0.6025490164756775, "train/det_cls.d4_loss": 0.5996688008308411, "train/det_cls.d5_loss": 0.5978189706802368, "train/det_reg.d0_loss": 2.3206000328063965, "train/det_reg.d1_loss": 2.2430005073547363, "train/det_reg.d2_loss": 2.2971720695495605, "train/det_reg.d3_loss": 2.326296091079712, "train/det_reg.d4_loss": 2.4025936126708984, "train/det_reg.d5_loss": 2.447450876235962, "train/wp.d0_loss": 1.0632336139678955, "train/wp.d1_loss": 1.033448338508606, "train/wp.d2_loss": 1.0357564687728882, "train/wp.d3_loss": 1.0241985321044922, "train/wp.d4_loss": 1.0321481227874756, "train/wp.d5_loss": 1.0324318408966064, "train/wp": 1.0324318408966064, "train/attnmap_loss": 1.3252170085906982, "train/loss": 25.08110809326172, "train/grad_norm": 20.535795211791992, "learning_rate": 8.053333333333333e-05, "momentum": 0.9, "_runtime": 338.4082553386688, "_timestamp": 1676689019.8115907, "_step": 53}
{"train/det_cls.d0_loss": 0.5439799427986145, "train/det_cls.d1_loss": 0.5598249435424805, "train/det_cls.d2_loss": 0.5531656742095947, "train/det_cls.d3_loss": 0.5825774073600769, "train/det_cls.d4_loss": 0.5840411186218262, "train/det_cls.d5_loss": 0.584973931312561, "train/det_reg.d0_loss": 2.495305061340332, "train/det_reg.d1_loss": 2.4260220527648926, "train/det_reg.d2_loss": 2.429888963699341, "train/det_reg.d3_loss": 2.375102996826172, "train/det_reg.d4_loss": 2.3937618732452393, "train/det_reg.d5_loss": 2.3975064754486084, "train/wp.d0_loss": 0.9611800909042358, "train/wp.d1_loss": 0.9069082736968994, "train/wp.d2_loss": 0.9036058783531189, "train/wp.d3_loss": 0.9123024940490723, "train/wp.d4_loss": 0.9026897549629211, "train/wp.d5_loss": 0.8990435600280762, "train/wp": 0.8990435600280762, "train/attnmap_loss": 1.4341187477111816, "train/loss": 24.84600067138672, "train/grad_norm": 22.982433319091797, "learning_rate": 8.079999999999999e-05, "momentum": 0.9, "_runtime": 341.6463112831116, "_timestamp": 1676689023.0496466, "_step": 54}
{"train/det_cls.d0_loss": 0.5450303554534912, "train/det_cls.d1_loss": 0.5747043490409851, "train/det_cls.d2_loss": 0.5751140117645264, "train/det_cls.d3_loss": 0.5961418747901917, "train/det_cls.d4_loss": 0.5946583151817322, "train/det_cls.d5_loss": 0.5922211408615112, "train/det_reg.d0_loss": 2.398965358734131, "train/det_reg.d1_loss": 2.314279079437256, "train/det_reg.d2_loss": 2.317181348800659, "train/det_reg.d3_loss": 2.32319712638855, "train/det_reg.d4_loss": 2.3154847621917725, "train/det_reg.d5_loss": 2.2879889011383057, "train/wp.d0_loss": 1.0916669368743896, "train/wp.d1_loss": 1.043576955795288, "train/wp.d2_loss": 1.0316485166549683, "train/wp.d3_loss": 1.044313669204712, "train/wp.d4_loss": 1.0508787631988525, "train/wp.d5_loss": 1.0461033582687378, "train/wp": 1.0461033582687378, "train/attnmap_loss": 1.8467020988464355, "train/loss": 25.589855194091797, "train/grad_norm": 24.58687400817871, "learning_rate": 8.106666666666664e-05, "momentum": 0.9, "_runtime": 344.6337192058563, "_timestamp": 1676689026.0370545, "_step": 55}
{"train/det_cls.d0_loss": 0.5523231029510498, "train/det_cls.d1_loss": 0.5774833559989929, "train/det_cls.d2_loss": 0.580642580986023, "train/det_cls.d3_loss": 0.6054777503013611, "train/det_cls.d4_loss": 0.5988906621932983, "train/det_cls.d5_loss": 0.596957802772522, "train/det_reg.d0_loss": 2.3723464012145996, "train/det_reg.d1_loss": 2.2870044708251953, "train/det_reg.d2_loss": 2.3052330017089844, "train/det_reg.d3_loss": 2.2950375080108643, "train/det_reg.d4_loss": 2.246561050415039, "train/det_reg.d5_loss": 2.302489757537842, "train/wp.d0_loss": 0.961516261100769, "train/wp.d1_loss": 0.9448471069335938, "train/wp.d2_loss": 0.9567227363586426, "train/wp.d3_loss": 0.9559898972511292, "train/wp.d4_loss": 0.9446828365325928, "train/wp.d5_loss": 0.9409822225570679, "train/wp": 0.9409822225570679, "train/attnmap_loss": 1.903454065322876, "train/loss": 24.92864227294922, "train/grad_norm": 21.855724334716797, "learning_rate": 8.133333333333332e-05, "momentum": 0.9, "_runtime": 347.4540355205536, "_timestamp": 1676689028.8573709, "_step": 56}
{"train/det_cls.d0_loss": 0.537316083908081, "train/det_cls.d1_loss": 0.5583497285842896, "train/det_cls.d2_loss": 0.5643607378005981, "train/det_cls.d3_loss": 0.5873761177062988, "train/det_cls.d4_loss": 0.5813493728637695, "train/det_cls.d5_loss": 0.5750760436058044, "train/det_reg.d0_loss": 2.4147770404815674, "train/det_reg.d1_loss": 2.316387176513672, "train/det_reg.d2_loss": 2.3403573036193848, "train/det_reg.d3_loss": 2.3232505321502686, "train/det_reg.d4_loss": 2.2925212383270264, "train/det_reg.d5_loss": 2.383429527282715, "train/wp.d0_loss": 1.0432212352752686, "train/wp.d1_loss": 1.023818016052246, "train/wp.d2_loss": 1.0386943817138672, "train/wp.d3_loss": 1.010179042816162, "train/wp.d4_loss": 1.0253641605377197, "train/wp.d5_loss": 1.0258171558380127, "train/wp": 1.0258171558380127, "train/attnmap_loss": 1.3265992403030396, "train/loss": 24.968242645263672, "train/grad_norm": 33.55426025390625, "learning_rate": 8.159999999999999e-05, "momentum": 0.9, "_runtime": 350.64044213294983, "_timestamp": 1676689032.0437775, "_step": 57}
{"train/det_cls.d0_loss": 0.5407097935676575, "train/det_cls.d1_loss": 0.5590685606002808, "train/det_cls.d2_loss": 0.563143789768219, "train/det_cls.d3_loss": 0.5930410623550415, "train/det_cls.d4_loss": 0.5788854360580444, "train/det_cls.d5_loss": 0.5731669664382935, "train/det_reg.d0_loss": 2.3432672023773193, "train/det_reg.d1_loss": 2.323240280151367, "train/det_reg.d2_loss": 2.3560068607330322, "train/det_reg.d3_loss": 2.3507933616638184, "train/det_reg.d4_loss": 2.356651544570923, "train/det_reg.d5_loss": 2.47446870803833, "train/wp.d0_loss": 1.000959038734436, "train/wp.d1_loss": 0.9865087866783142, "train/wp.d2_loss": 0.9737159609794617, "train/wp.d3_loss": 0.966732919216156, "train/wp.d4_loss": 0.9852212071418762, "train/wp.d5_loss": 0.9842516183853149, "train/wp": 0.9842516183853149, "train/attnmap_loss": 1.407932996749878, "train/loss": 24.917766571044922, "train/grad_norm": 27.503311157226562, "learning_rate": 8.186666666666665e-05, "momentum": 0.9, "_runtime": 353.9296200275421, "_timestamp": 1676689035.3329554, "_step": 58}
{"train/det_cls.d0_loss": 0.5399608612060547, "train/det_cls.d1_loss": 0.5603386163711548, "train/det_cls.d2_loss": 0.5627954602241516, "train/det_cls.d3_loss": 0.5781137943267822, "train/det_cls.d4_loss": 0.5759155750274658, "train/det_cls.d5_loss": 0.5741467475891113, "train/det_reg.d0_loss": 2.348905324935913, "train/det_reg.d1_loss": 2.3040971755981445, "train/det_reg.d2_loss": 2.3231942653656006, "train/det_reg.d3_loss": 2.312556743621826, "train/det_reg.d4_loss": 2.3234450817108154, "train/det_reg.d5_loss": 2.471172332763672, "train/wp.d0_loss": 1.087289810180664, "train/wp.d1_loss": 1.0624871253967285, "train/wp.d2_loss": 1.0550565719604492, "train/wp.d3_loss": 1.0515512228012085, "train/wp.d4_loss": 1.0510988235473633, "train/wp.d5_loss": 1.065629243850708, "train/wp": 1.065629243850708, "train/attnmap_loss": 2.1022567749023438, "train/loss": 25.95001220703125, "train/grad_norm": 30.195205688476562, "learning_rate": 8.213333333333333e-05, "momentum": 0.9, "_runtime": 356.9118297100067, "_timestamp": 1676689038.315165, "_step": 59}
{"train/det_cls.d0_loss": 0.5480480194091797, "train/det_cls.d1_loss": 0.5584297180175781, "train/det_cls.d2_loss": 0.5511990785598755, "train/det_cls.d3_loss": 0.5816892385482788, "train/det_cls.d4_loss": 0.5803673267364502, "train/det_cls.d5_loss": 0.577405571937561, "train/det_reg.d0_loss": 2.3485565185546875, "train/det_reg.d1_loss": 2.3145532608032227, "train/det_reg.d2_loss": 2.305577278137207, "train/det_reg.d3_loss": 2.253281593322754, "train/det_reg.d4_loss": 2.3065643310546875, "train/det_reg.d5_loss": 2.4339466094970703, "train/wp.d0_loss": 0.9947222471237183, "train/wp.d1_loss": 0.9926940202713013, "train/wp.d2_loss": 0.9829310178756714, "train/wp.d3_loss": 0.9805671572685242, "train/wp.d4_loss": 0.9937235713005066, "train/wp.d5_loss": 1.0014508962631226, "train/wp": 1.0014508962631226, "train/attnmap_loss": 1.487654685974121, "train/loss": 24.79336166381836, "train/grad_norm": 29.64014434814453, "learning_rate": 8.239999999999998e-05, "momentum": 0.9, "_runtime": 359.7333753108978, "_timestamp": 1676689041.1367106, "_step": 60}
{"train/det_cls.d0_loss": 0.5567654967308044, "train/det_cls.d1_loss": 0.5614382028579712, "train/det_cls.d2_loss": 0.5580735802650452, "train/det_cls.d3_loss": 0.5785509347915649, "train/det_cls.d4_loss": 0.578513503074646, "train/det_cls.d5_loss": 0.5709065198898315, "train/det_reg.d0_loss": 2.3113372325897217, "train/det_reg.d1_loss": 2.264256238937378, "train/det_reg.d2_loss": 2.256491184234619, "train/det_reg.d3_loss": 2.232353925704956, "train/det_reg.d4_loss": 2.2411704063415527, "train/det_reg.d5_loss": 2.366771936416626, "train/wp.d0_loss": 1.0303817987442017, "train/wp.d1_loss": 1.0089614391326904, "train/wp.d2_loss": 1.003969430923462, "train/wp.d3_loss": 1.0052824020385742, "train/wp.d4_loss": 0.9839663505554199, "train/wp.d5_loss": 0.9960086345672607, "train/wp": 0.9960086345672607, "train/attnmap_loss": 1.9014734029769897, "train/loss": 25.006671905517578, "train/grad_norm": 33.42014694213867, "learning_rate": 8.266666666666665e-05, "momentum": 0.9, "_runtime": 363.0847849845886, "_timestamp": 1676689044.4881203, "_step": 61}
{"train/det_cls.d0_loss": 0.5228260159492493, "train/det_cls.d1_loss": 0.5302759408950806, "train/det_cls.d2_loss": 0.5312880873680115, "train/det_cls.d3_loss": 0.5485434532165527, "train/det_cls.d4_loss": 0.545446515083313, "train/det_cls.d5_loss": 0.5459921360015869, "train/det_reg.d0_loss": 2.424410104751587, "train/det_reg.d1_loss": 2.3696775436401367, "train/det_reg.d2_loss": 2.359079122543335, "train/det_reg.d3_loss": 2.356220006942749, "train/det_reg.d4_loss": 2.4334325790405273, "train/det_reg.d5_loss": 2.5435221195220947, "train/wp.d0_loss": 1.0971795320510864, "train/wp.d1_loss": 1.066712498664856, "train/wp.d2_loss": 1.0775792598724365, "train/wp.d3_loss": 1.073312520980835, "train/wp.d4_loss": 1.0636570453643799, "train/wp.d5_loss": 1.0572936534881592, "train/wp": 1.0572936534881592, "train/attnmap_loss": 1.25041925907135, "train/loss": 25.396865844726562, "train/grad_norm": 16.492937088012695, "learning_rate": 8.293333333333333e-05, "momentum": 0.9, "_runtime": 366.42589354515076, "_timestamp": 1676689047.8292289, "_step": 62}
{"train/det_cls.d0_loss": 0.5362709760665894, "train/det_cls.d1_loss": 0.5358227491378784, "train/det_cls.d2_loss": 0.5336334109306335, "train/det_cls.d3_loss": 0.5634163618087769, "train/det_cls.d4_loss": 0.5574302077293396, "train/det_cls.d5_loss": 0.5528157353401184, "train/det_reg.d0_loss": 2.4452157020568848, "train/det_reg.d1_loss": 2.4001893997192383, "train/det_reg.d2_loss": 2.3901286125183105, "train/det_reg.d3_loss": 2.3754618167877197, "train/det_reg.d4_loss": 2.4991614818573, "train/det_reg.d5_loss": 2.6306214332580566, "train/wp.d0_loss": 1.032175064086914, "train/wp.d1_loss": 1.038295030593872, "train/wp.d2_loss": 1.0223881006240845, "train/wp.d3_loss": 1.02680242061615, "train/wp.d4_loss": 1.0294437408447266, "train/wp.d5_loss": 1.0206363201141357, "train/wp": 1.0206363201141357, "train/attnmap_loss": 1.5088547468185425, "train/loss": 25.698762893676758, "train/grad_norm": 21.37513542175293, "learning_rate": 8.319999999999999e-05, "momentum": 0.9, "_runtime": 369.50130915641785, "_timestamp": 1676689050.9046445, "_step": 63}
{"train/det_cls.d0_loss": 0.547692060470581, "train/det_cls.d1_loss": 0.5352615118026733, "train/det_cls.d2_loss": 0.5322142243385315, "train/det_cls.d3_loss": 0.5626986622810364, "train/det_cls.d4_loss": 0.560269296169281, "train/det_cls.d5_loss": 0.5561052560806274, "train/det_reg.d0_loss": 2.2877731323242188, "train/det_reg.d1_loss": 2.280003309249878, "train/det_reg.d2_loss": 2.296199321746826, "train/det_reg.d3_loss": 2.288397789001465, "train/det_reg.d4_loss": 2.355531692504883, "train/det_reg.d5_loss": 2.494197368621826, "train/wp.d0_loss": 1.0935003757476807, "train/wp.d1_loss": 1.0783770084381104, "train/wp.d2_loss": 1.0833663940429688, "train/wp.d3_loss": 1.079160213470459, "train/wp.d4_loss": 1.0699502229690552, "train/wp.d5_loss": 1.0762181282043457, "train/wp": 1.0762181282043457, "train/attnmap_loss": 1.4219673871994019, "train/loss": 25.198881149291992, "train/grad_norm": 22.047786712646484, "learning_rate": 8.346666666666664e-05, "momentum": 0.9, "_runtime": 372.44046902656555, "_timestamp": 1676689053.8438044, "_step": 64}
{"train/det_cls.d0_loss": 0.533211886882782, "train/det_cls.d1_loss": 0.5281753540039062, "train/det_cls.d2_loss": 0.5269733667373657, "train/det_cls.d3_loss": 0.5466437339782715, "train/det_cls.d4_loss": 0.5469481945037842, "train/det_cls.d5_loss": 0.5539947748184204, "train/det_reg.d0_loss": 2.331237316131592, "train/det_reg.d1_loss": 2.2848854064941406, "train/det_reg.d2_loss": 2.30574631690979, "train/det_reg.d3_loss": 2.319028854370117, "train/det_reg.d4_loss": 2.3641951084136963, "train/det_reg.d5_loss": 2.470644474029541, "train/wp.d0_loss": 1.0921400785446167, "train/wp.d1_loss": 1.0828948020935059, "train/wp.d2_loss": 1.0721654891967773, "train/wp.d3_loss": 1.072442650794983, "train/wp.d4_loss": 1.061887502670288, "train/wp.d5_loss": 1.0781059265136719, "train/wp": 1.0781059265136719, "train/attnmap_loss": 1.593808650970459, "train/loss": 25.365131378173828, "train/grad_norm": 24.855152130126953, "learning_rate": 8.373333333333333e-05, "momentum": 0.9, "_runtime": 375.70779752731323, "_timestamp": 1676689057.1111329, "_step": 65}
{"train/det_cls.d0_loss": 0.5468236804008484, "train/det_cls.d1_loss": 0.5419721603393555, "train/det_cls.d2_loss": 0.5355252027511597, "train/det_cls.d3_loss": 0.5616840720176697, "train/det_cls.d4_loss": 0.5464166402816772, "train/det_cls.d5_loss": 0.5525298714637756, "train/det_reg.d0_loss": 2.279670476913452, "train/det_reg.d1_loss": 2.267916679382324, "train/det_reg.d2_loss": 2.301586627960205, "train/det_reg.d3_loss": 2.314729690551758, "train/det_reg.d4_loss": 2.3126883506774902, "train/det_reg.d5_loss": 2.4082257747650146, "train/wp.d0_loss": 1.0631885528564453, "train/wp.d1_loss": 1.036515235900879, "train/wp.d2_loss": 1.0273759365081787, "train/wp.d3_loss": 1.0414766073226929, "train/wp.d4_loss": 1.032949686050415, "train/wp.d5_loss": 1.0183372497558594, "train/wp": 1.0183372497558594, "train/attnmap_loss": 1.4693095684051514, "train/loss": 24.858922958374023, "train/grad_norm": 27.095632553100586, "learning_rate": 8.4e-05, "momentum": 0.9, "_runtime": 379.27963972091675, "_timestamp": 1676689060.682975, "_step": 66}
{"train/det_cls.d0_loss": 0.5914802551269531, "train/det_cls.d1_loss": 0.5679552555084229, "train/det_cls.d2_loss": 0.5707057118415833, "train/det_cls.d3_loss": 0.5867772102355957, "train/det_cls.d4_loss": 0.5796231031417847, "train/det_cls.d5_loss": 0.5875834822654724, "train/det_reg.d0_loss": 2.341582775115967, "train/det_reg.d1_loss": 2.3213284015655518, "train/det_reg.d2_loss": 2.360344171524048, "train/det_reg.d3_loss": 2.338416337966919, "train/det_reg.d4_loss": 2.3054771423339844, "train/det_reg.d5_loss": 2.309506893157959, "train/wp.d0_loss": 1.0391860008239746, "train/wp.d1_loss": 1.0339641571044922, "train/wp.d2_loss": 1.030822515487671, "train/wp.d3_loss": 1.0366429090499878, "train/wp.d4_loss": 1.018523931503296, "train/wp.d5_loss": 1.007662057876587, "train/wp": 1.007662057876587, "train/attnmap_loss": 1.8871355056762695, "train/loss": 25.51471710205078, "train/grad_norm": 23.907726287841797, "learning_rate": 8.426666666666665e-05, "momentum": 0.9, "_runtime": 382.26664876937866, "_timestamp": 1676689063.669984, "_step": 67}
