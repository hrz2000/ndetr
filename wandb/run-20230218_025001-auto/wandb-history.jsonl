{"train/det_cls.d0_loss": 2.3034348487854004, "train/det_cls.d1_loss": 2.287911891937256, "train/det_cls.d2_loss": 2.382718086242676, "train/det_cls.d3_loss": 2.3177640438079834, "train/det_cls.d4_loss": 2.309373378753662, "train/det_cls.d5_loss": 2.2687909603118896, "train/det_reg.d0_loss": 4.363675117492676, "train/det_reg.d1_loss": 4.413113594055176, "train/det_reg.d2_loss": 4.498111248016357, "train/det_reg.d3_loss": 4.522331237792969, "train/det_reg.d4_loss": 4.603835105895996, "train/det_reg.d5_loss": 4.636998176574707, "train/wp.d0_loss": 1.842652440071106, "train/wp.d1_loss": 1.982372760772705, "train/wp.d2_loss": 2.036746025085449, "train/wp.d3_loss": 1.9962773323059082, "train/wp.d4_loss": 2.1991686820983887, "train/wp.d5_loss": 2.2473297119140625, "train/wp": 2.2473297119140625, "train/attnmap_loss": 2.0782041549682617, "train/loss": 55.29080581665039, "train/grad_norm": 82.50382232666016, "learning_rate": 6.666666666666666e-05, "momentum": 0.9, "_runtime": 35.16291046142578, "_timestamp": 1676688616.14066, "_step": 1}
{"train/det_cls.d0_loss": 2.1787142753601074, "train/det_cls.d1_loss": 2.1009485721588135, "train/det_cls.d2_loss": 2.116443157196045, "train/det_cls.d3_loss": 2.123551607131958, "train/det_cls.d4_loss": 2.131368637084961, "train/det_cls.d5_loss": 2.076732873916626, "train/det_reg.d0_loss": 4.117105007171631, "train/det_reg.d1_loss": 4.043898105621338, "train/det_reg.d2_loss": 4.101365089416504, "train/det_reg.d3_loss": 4.068783760070801, "train/det_reg.d4_loss": 3.950881242752075, "train/det_reg.d5_loss": 3.793900489807129, "train/wp.d0_loss": 1.5155487060546875, "train/wp.d1_loss": 1.5937373638153076, "train/wp.d2_loss": 1.5722402334213257, "train/wp.d3_loss": 1.4521116018295288, "train/wp.d4_loss": 1.5428087711334229, "train/wp.d5_loss": 1.6232787370681763, "train/wp": 1.6232787370681763, "train/attnmap_loss": 1.746109962463379, "train/loss": 47.849525451660156, "train/grad_norm": 57.068519592285156, "learning_rate": 6.693333333333331e-05, "momentum": 0.9, "_runtime": 40.593799114227295, "_timestamp": 1676688621.5715487, "_step": 2}
{"train/det_cls.d0_loss": 2.0758533477783203, "train/det_cls.d1_loss": 1.9605954885482788, "train/det_cls.d2_loss": 1.9826340675354004, "train/det_cls.d3_loss": 1.9867022037506104, "train/det_cls.d4_loss": 1.9784197807312012, "train/det_cls.d5_loss": 1.9605598449707031, "train/det_reg.d0_loss": 4.150177001953125, "train/det_reg.d1_loss": 4.055257320404053, "train/det_reg.d2_loss": 4.0134711265563965, "train/det_reg.d3_loss": 3.861295700073242, "train/det_reg.d4_loss": 3.6229350566864014, "train/det_reg.d5_loss": 3.4024062156677246, "train/wp.d0_loss": 1.6533329486846924, "train/wp.d1_loss": 1.6472489833831787, "train/wp.d2_loss": 1.6508874893188477, "train/wp.d3_loss": 1.6339998245239258, "train/wp.d4_loss": 1.649440050125122, "train/wp.d5_loss": 1.5508941411972046, "train/wp": 1.5508941411972046, "train/attnmap_loss": 1.8582055568695068, "train/loss": 46.694313049316406, "train/grad_norm": 43.32844924926758, "learning_rate": 6.72e-05, "momentum": 0.9, "_runtime": 45.00933766365051, "_timestamp": 1676688625.9870872, "_step": 3}
{"train/det_cls.d0_loss": 1.9348325729370117, "train/det_cls.d1_loss": 1.8714935779571533, "train/det_cls.d2_loss": 1.8571585416793823, "train/det_cls.d3_loss": 1.8715015649795532, "train/det_cls.d4_loss": 1.766968011856079, "train/det_cls.d5_loss": 1.7632938623428345, "train/det_reg.d0_loss": 4.03743314743042, "train/det_reg.d1_loss": 3.8236074447631836, "train/det_reg.d2_loss": 3.670835256576538, "train/det_reg.d3_loss": 3.4268798828125, "train/det_reg.d4_loss": 3.2428104877471924, "train/det_reg.d5_loss": 3.0622098445892334, "train/wp.d0_loss": 1.6274030208587646, "train/wp.d1_loss": 1.5760478973388672, "train/wp.d2_loss": 1.6370396614074707, "train/wp.d3_loss": 1.6544451713562012, "train/wp.d4_loss": 1.6592059135437012, "train/wp.d5_loss": 1.5154869556427002, "train/wp": 1.5154869556427002, "train/attnmap_loss": 1.357749104499817, "train/loss": 43.35640335083008, "train/grad_norm": 51.319759368896484, "learning_rate": 6.746666666666666e-05, "momentum": 0.9, "_runtime": 48.046223640441895, "_timestamp": 1676688629.0239732, "_step": 4}
{"train/det_cls.d0_loss": 1.8262856006622314, "train/det_cls.d1_loss": 1.7775828838348389, "train/det_cls.d2_loss": 1.6790797710418701, "train/det_cls.d3_loss": 1.6807674169540405, "train/det_cls.d4_loss": 1.5741679668426514, "train/det_cls.d5_loss": 1.6228324174880981, "train/det_reg.d0_loss": 3.825930595397949, "train/det_reg.d1_loss": 3.5823707580566406, "train/det_reg.d2_loss": 3.4272444248199463, "train/det_reg.d3_loss": 3.2073814868927, "train/det_reg.d4_loss": 2.9207966327667236, "train/det_reg.d5_loss": 2.919734477996826, "train/wp.d0_loss": 1.460848331451416, "train/wp.d1_loss": 1.42130446434021, "train/wp.d2_loss": 1.4621555805206299, "train/wp.d3_loss": 1.4508496522903442, "train/wp.d4_loss": 1.451413631439209, "train/wp.d5_loss": 1.3415957689285278, "train/wp": 1.3415957689285278, "train/attnmap_loss": 2.6800270080566406, "train/loss": 41.3123664855957, "train/grad_norm": 46.87087631225586, "learning_rate": 6.773333333333332e-05, "momentum": 0.9, "_runtime": 51.558977365493774, "_timestamp": 1676688632.536727, "_step": 5}
{"train/det_cls.d0_loss": 1.760115146636963, "train/det_cls.d1_loss": 1.6564114093780518, "train/det_cls.d2_loss": 1.5212972164154053, "train/det_cls.d3_loss": 1.5291012525558472, "train/det_cls.d4_loss": 1.4824814796447754, "train/det_cls.d5_loss": 1.509504795074463, "train/det_reg.d0_loss": 3.7432994842529297, "train/det_reg.d1_loss": 3.4694888591766357, "train/det_reg.d2_loss": 3.339674711227417, "train/det_reg.d3_loss": 3.131791353225708, "train/det_reg.d4_loss": 2.9671432971954346, "train/det_reg.d5_loss": 3.0561795234680176, "train/wp.d0_loss": 1.488630771636963, "train/wp.d1_loss": 1.4613890647888184, "train/wp.d2_loss": 1.4882539510726929, "train/wp.d3_loss": 1.4933440685272217, "train/wp.d4_loss": 1.4740090370178223, "train/wp.d5_loss": 1.374215841293335, "train/wp": 1.374215841293335, "train/attnmap_loss": 1.6775659322738647, "train/loss": 39.623897552490234, "train/grad_norm": 44.599910736083984, "learning_rate": 6.8e-05, "momentum": 0.9, "_runtime": 54.996628284454346, "_timestamp": 1676688635.9743779, "_step": 6}
{"train/det_cls.d0_loss": 1.6448183059692383, "train/det_cls.d1_loss": 1.5555524826049805, "train/det_cls.d2_loss": 1.4008840322494507, "train/det_cls.d3_loss": 1.4096134901046753, "train/det_cls.d4_loss": 1.3365083932876587, "train/det_cls.d5_loss": 1.3737688064575195, "train/det_reg.d0_loss": 3.7102267742156982, "train/det_reg.d1_loss": 3.402526378631592, "train/det_reg.d2_loss": 3.2421929836273193, "train/det_reg.d3_loss": 2.9175877571105957, "train/det_reg.d4_loss": 2.8609137535095215, "train/det_reg.d5_loss": 3.217177152633667, "train/wp.d0_loss": 1.4044935703277588, "train/wp.d1_loss": 1.340085506439209, "train/wp.d2_loss": 1.3201066255569458, "train/wp.d3_loss": 1.2730624675750732, "train/wp.d4_loss": 1.2713613510131836, "train/wp.d5_loss": 1.2455651760101318, "train/wp": 1.2455651760101318, "train/attnmap_loss": 1.7726722955703735, "train/loss": 37.699119567871094, "train/grad_norm": 35.59739303588867, "learning_rate": 6.826666666666665e-05, "momentum": 0.9, "_runtime": 58.158427715301514, "_timestamp": 1676688639.1361773, "_step": 7}
{"train/det_cls.d0_loss": 1.5886101722717285, "train/det_cls.d1_loss": 1.4600694179534912, "train/det_cls.d2_loss": 1.299105167388916, "train/det_cls.d3_loss": 1.2874066829681396, "train/det_cls.d4_loss": 1.2116003036499023, "train/det_cls.d5_loss": 1.268221378326416, "train/det_reg.d0_loss": 3.6773202419281006, "train/det_reg.d1_loss": 3.409360885620117, "train/det_reg.d2_loss": 3.218865394592285, "train/det_reg.d3_loss": 2.950050115585327, "train/det_reg.d4_loss": 3.083608865737915, "train/det_reg.d5_loss": 3.3483550548553467, "train/wp.d0_loss": 1.3211677074432373, "train/wp.d1_loss": 1.2718290090560913, "train/wp.d2_loss": 1.2507520914077759, "train/wp.d3_loss": 1.2063132524490356, "train/wp.d4_loss": 1.23714280128479, "train/wp.d5_loss": 1.2122858762741089, "train/wp": 1.2122858762741089, "train/attnmap_loss": 1.5682384967803955, "train/loss": 36.870304107666016, "train/grad_norm": 33.93437957763672, "learning_rate": 6.853333333333331e-05, "momentum": 0.9, "_runtime": 61.19971704483032, "_timestamp": 1676688642.1774666, "_step": 8}
{"train/det_cls.d0_loss": 1.5019500255584717, "train/det_cls.d1_loss": 1.3153730630874634, "train/det_cls.d2_loss": 1.1904518604278564, "train/det_cls.d3_loss": 1.177933692932129, "train/det_cls.d4_loss": 1.1048332452774048, "train/det_cls.d5_loss": 1.1523959636688232, "train/det_reg.d0_loss": 3.738583564758301, "train/det_reg.d1_loss": 3.4211740493774414, "train/det_reg.d2_loss": 3.1034765243530273, "train/det_reg.d3_loss": 2.9091200828552246, "train/det_reg.d4_loss": 3.0703814029693604, "train/det_reg.d5_loss": 3.3092403411865234, "train/wp.d0_loss": 1.3322532176971436, "train/wp.d1_loss": 1.2634971141815186, "train/wp.d2_loss": 1.248547911643982, "train/wp.d3_loss": 1.2109177112579346, "train/wp.d4_loss": 1.2603355646133423, "train/wp.d5_loss": 1.2128653526306152, "train/wp": 1.2128653526306152, "train/attnmap_loss": 2.508117198944092, "train/loss": 37.03144836425781, "train/grad_norm": 36.78483581542969, "learning_rate": 6.879999999999999e-05, "momentum": 0.9, "_runtime": 64.69453263282776, "_timestamp": 1676688645.6722822, "_step": 9}
{"train/det_cls.d0_loss": 1.4175559282302856, "train/det_cls.d1_loss": 1.2304952144622803, "train/det_cls.d2_loss": 1.1103224754333496, "train/det_cls.d3_loss": 1.0714954137802124, "train/det_cls.d4_loss": 0.9964790344238281, "train/det_cls.d5_loss": 1.060807466506958, "train/det_reg.d0_loss": 3.574033260345459, "train/det_reg.d1_loss": 3.270174741744995, "train/det_reg.d2_loss": 3.0498251914978027, "train/det_reg.d3_loss": 2.875905990600586, "train/det_reg.d4_loss": 3.0608787536621094, "train/det_reg.d5_loss": 3.1971523761749268, "train/wp.d0_loss": 1.233107328414917, "train/wp.d1_loss": 1.1686248779296875, "train/wp.d2_loss": 1.1375142335891724, "train/wp.d3_loss": 1.1025233268737793, "train/wp.d4_loss": 1.1357532739639282, "train/wp.d5_loss": 1.1132642030715942, "train/wp": 1.1132642030715942, "train/attnmap_loss": 1.4763073921203613, "train/loss": 34.28221893310547, "train/grad_norm": 33.19377136230469, "learning_rate": 6.906666666666666e-05, "momentum": 0.9, "_runtime": 67.97519969940186, "_timestamp": 1676688648.9529493, "_step": 10}
{"train/det_cls.d0_loss": 1.3530669212341309, "train/det_cls.d1_loss": 1.1289448738098145, "train/det_cls.d2_loss": 1.0229686498641968, "train/det_cls.d3_loss": 0.9680291414260864, "train/det_cls.d4_loss": 0.9093039035797119, "train/det_cls.d5_loss": 0.9702954292297363, "train/det_reg.d0_loss": 3.490264415740967, "train/det_reg.d1_loss": 3.219611644744873, "train/det_reg.d2_loss": 3.0654609203338623, "train/det_reg.d3_loss": 2.966628313064575, "train/det_reg.d4_loss": 3.0915956497192383, "train/det_reg.d5_loss": 3.181356906890869, "train/wp.d0_loss": 1.3307148218154907, "train/wp.d1_loss": 1.222954511642456, "train/wp.d2_loss": 1.1950260400772095, "train/wp.d3_loss": 1.1381571292877197, "train/wp.d4_loss": 1.164182424545288, "train/wp.d5_loss": 1.1520706415176392, "train/wp": 1.1520706415176392, "train/attnmap_loss": 1.9852294921875, "train/loss": 34.55586624145508, "train/grad_norm": 35.93735885620117, "learning_rate": 6.933333333333332e-05, "momentum": 0.9, "_runtime": 71.13480472564697, "_timestamp": 1676688652.1125543, "_step": 11}
{"train/det_cls.d0_loss": 1.26138436794281, "train/det_cls.d1_loss": 1.0724375247955322, "train/det_cls.d2_loss": 0.9346984028816223, "train/det_cls.d3_loss": 0.8950433135032654, "train/det_cls.d4_loss": 0.8513860106468201, "train/det_cls.d5_loss": 0.8965442180633545, "train/det_reg.d0_loss": 3.4821810722351074, "train/det_reg.d1_loss": 3.181621551513672, "train/det_reg.d2_loss": 2.965287685394287, "train/det_reg.d3_loss": 3.0006208419799805, "train/det_reg.d4_loss": 3.084904193878174, "train/det_reg.d5_loss": 3.1140098571777344, "train/wp.d0_loss": 1.2560184001922607, "train/wp.d1_loss": 1.1709786653518677, "train/wp.d2_loss": 1.120048999786377, "train/wp.d3_loss": 1.0876961946487427, "train/wp.d4_loss": 1.1431057453155518, "train/wp.d5_loss": 1.1227542161941528, "train/wp": 1.1227542161941528, "train/attnmap_loss": 1.9316251277923584, "train/loss": 33.57234573364258, "train/grad_norm": 34.69054412841797, "learning_rate": 6.96e-05, "momentum": 0.9, "_runtime": 74.08329105377197, "_timestamp": 1676688655.0610406, "_step": 12}
{"train/det_cls.d0_loss": 1.200056791305542, "train/det_cls.d1_loss": 0.9923279285430908, "train/det_cls.d2_loss": 0.8922621011734009, "train/det_cls.d3_loss": 0.8260977864265442, "train/det_cls.d4_loss": 0.812026858329773, "train/det_cls.d5_loss": 0.8488129377365112, "train/det_reg.d0_loss": 3.4896161556243896, "train/det_reg.d1_loss": 3.1420540809631348, "train/det_reg.d2_loss": 2.909041166305542, "train/det_reg.d3_loss": 2.992239475250244, "train/det_reg.d4_loss": 2.995807647705078, "train/det_reg.d5_loss": 2.922797918319702, "train/wp.d0_loss": 1.278792142868042, "train/wp.d1_loss": 1.136033296585083, "train/wp.d2_loss": 1.1090471744537354, "train/wp.d3_loss": 1.050006628036499, "train/wp.d4_loss": 1.0857516527175903, "train/wp.d5_loss": 1.0654981136322021, "train/wp": 1.0654981136322021, "train/attnmap_loss": 1.988924264907837, "train/loss": 32.7371940612793, "train/grad_norm": 34.76673889160156, "learning_rate": 6.986666666666665e-05, "momentum": 0.9, "_runtime": 77.51408100128174, "_timestamp": 1676688658.4918306, "_step": 13}
{"train/det_cls.d0_loss": 1.1244678497314453, "train/det_cls.d1_loss": 0.909917950630188, "train/det_cls.d2_loss": 0.8138797283172607, "train/det_cls.d3_loss": 0.7634854316711426, "train/det_cls.d4_loss": 0.757928729057312, "train/det_cls.d5_loss": 0.7934180498123169, "train/det_reg.d0_loss": 3.547882080078125, "train/det_reg.d1_loss": 3.1390514373779297, "train/det_reg.d2_loss": 3.0170319080352783, "train/det_reg.d3_loss": 3.0787060260772705, "train/det_reg.d4_loss": 2.9796183109283447, "train/det_reg.d5_loss": 2.9243555068969727, "train/wp.d0_loss": 1.2480098009109497, "train/wp.d1_loss": 1.1058096885681152, "train/wp.d2_loss": 1.0607563257217407, "train/wp.d3_loss": 1.0323296785354614, "train/wp.d4_loss": 1.0585949420928955, "train/wp.d5_loss": 1.0544992685317993, "train/wp": 1.0544992685317993, "train/attnmap_loss": 1.4060720205307007, "train/loss": 31.815814971923828, "train/grad_norm": 32.74284362792969, "learning_rate": 7.013333333333332e-05, "momentum": 0.9, "_runtime": 80.83407878875732, "_timestamp": 1676688661.8118284, "_step": 14}
{"train/det_cls.d0_loss": 1.0127356052398682, "train/det_cls.d1_loss": 0.8309036493301392, "train/det_cls.d2_loss": 0.7353626489639282, "train/det_cls.d3_loss": 0.7000850439071655, "train/det_cls.d4_loss": 0.7171071767807007, "train/det_cls.d5_loss": 0.735543966293335, "train/det_reg.d0_loss": 3.3615951538085938, "train/det_reg.d1_loss": 2.966702938079834, "train/det_reg.d2_loss": 2.8408989906311035, "train/det_reg.d3_loss": 3.00480580329895, "train/det_reg.d4_loss": 2.8747711181640625, "train/det_reg.d5_loss": 2.8663320541381836, "train/wp.d0_loss": 1.176450490951538, "train/wp.d1_loss": 1.0477063655853271, "train/wp.d2_loss": 1.0059740543365479, "train/wp.d3_loss": 1.000131368637085, "train/wp.d4_loss": 1.0311082601547241, "train/wp.d5_loss": 1.0369610786437988, "train/wp": 1.0369610786437988, "train/attnmap_loss": 1.5889941453933716, "train/loss": 30.534170150756836, "train/grad_norm": 32.152957916259766, "learning_rate": 7.04e-05, "momentum": 0.9, "_runtime": 84.0272262096405, "_timestamp": 1676688665.0049758, "_step": 15}
{"train/det_cls.d0_loss": 0.9868376851081848, "train/det_cls.d1_loss": 0.8058497905731201, "train/det_cls.d2_loss": 0.7120084166526794, "train/det_cls.d3_loss": 0.678381621837616, "train/det_cls.d4_loss": 0.6838398575782776, "train/det_cls.d5_loss": 0.7134336233139038, "train/det_reg.d0_loss": 3.2838735580444336, "train/det_reg.d1_loss": 3.019355535507202, "train/det_reg.d2_loss": 3.0263986587524414, "train/det_reg.d3_loss": 3.076653480529785, "train/det_reg.d4_loss": 2.8975698947906494, "train/det_reg.d5_loss": 2.787217617034912, "train/wp.d0_loss": 1.2125182151794434, "train/wp.d1_loss": 1.1246672868728638, "train/wp.d2_loss": 1.090185523033142, "train/wp.d3_loss": 1.0757808685302734, "train/wp.d4_loss": 1.096739649772644, "train/wp.d5_loss": 1.08830988407135, "train/wp": 1.08830988407135, "train/attnmap_loss": 1.478493094444275, "train/loss": 30.83811378479004, "train/grad_norm": 35.54008483886719, "learning_rate": 7.066666666666666e-05, "momentum": 0.9, "_runtime": 87.06248450279236, "_timestamp": 1676688668.040234, "_step": 16}
{"train/det_cls.d0_loss": 0.9055492281913757, "train/det_cls.d1_loss": 0.7435725331306458, "train/det_cls.d2_loss": 0.6830767393112183, "train/det_cls.d3_loss": 0.6612053513526917, "train/det_cls.d4_loss": 0.6615298390388489, "train/det_cls.d5_loss": 0.6722545027732849, "train/det_reg.d0_loss": 3.1973824501037598, "train/det_reg.d1_loss": 2.8948800563812256, "train/det_reg.d2_loss": 2.891195774078369, "train/det_reg.d3_loss": 2.9803237915039062, "train/det_reg.d4_loss": 2.859508991241455, "train/det_reg.d5_loss": 2.9072659015655518, "train/wp.d0_loss": 1.1954114437103271, "train/wp.d1_loss": 1.0311130285263062, "train/wp.d2_loss": 1.000896692276001, "train/wp.d3_loss": 0.9877456426620483, "train/wp.d4_loss": 0.9943699240684509, "train/wp.d5_loss": 0.9928187727928162, "train/wp": 0.9928187727928162, "train/attnmap_loss": 1.6921947002410889, "train/loss": 29.95229721069336, "train/grad_norm": 31.559507369995117, "learning_rate": 7.093333333333331e-05, "momentum": 0.9, "_runtime": 90.55314660072327, "_timestamp": 1676688671.5308962, "_step": 17}
{"train/det_cls.d0_loss": 0.8385083675384521, "train/det_cls.d1_loss": 0.6963956356048584, "train/det_cls.d2_loss": 0.6497070789337158, "train/det_cls.d3_loss": 0.628434956073761, "train/det_cls.d4_loss": 0.6316964030265808, "train/det_cls.d5_loss": 0.6283780932426453, "train/det_reg.d0_loss": 3.2414050102233887, "train/det_reg.d1_loss": 2.8639230728149414, "train/det_reg.d2_loss": 2.896592855453491, "train/det_reg.d3_loss": 2.9421029090881348, "train/det_reg.d4_loss": 2.921048164367676, "train/det_reg.d5_loss": 3.0150089263916016, "train/wp.d0_loss": 1.1522512435913086, "train/wp.d1_loss": 1.0337848663330078, "train/wp.d2_loss": 1.0094211101531982, "train/wp.d3_loss": 0.993567943572998, "train/wp.d4_loss": 1.0021965503692627, "train/wp.d5_loss": 0.9802135229110718, "train/wp": 0.9802135229110718, "train/attnmap_loss": 1.7319025993347168, "train/loss": 29.856536865234375, "train/grad_norm": 24.18324089050293, "learning_rate": 7.12e-05, "momentum": 0.9, "_runtime": 93.80283522605896, "_timestamp": 1676688674.7805848, "_step": 18}
{"train/det_cls.d0_loss": 0.7893250584602356, "train/det_cls.d1_loss": 0.6751999258995056, "train/det_cls.d2_loss": 0.6362748742103577, "train/det_cls.d3_loss": 0.6177552938461304, "train/det_cls.d4_loss": 0.6078606247901917, "train/det_cls.d5_loss": 0.6014497876167297, "train/det_reg.d0_loss": 3.161752223968506, "train/det_reg.d1_loss": 2.8250246047973633, "train/det_reg.d2_loss": 2.893167495727539, "train/det_reg.d3_loss": 2.811091899871826, "train/det_reg.d4_loss": 2.835721492767334, "train/det_reg.d5_loss": 3.010688543319702, "train/wp.d0_loss": 1.1585807800292969, "train/wp.d1_loss": 1.075944423675537, "train/wp.d2_loss": 1.0653914213180542, "train/wp.d3_loss": 1.0487877130508423, "train/wp.d4_loss": 1.0528336763381958, "train/wp.d5_loss": 1.0630617141723633, "train/wp": 1.0630617141723633, "train/attnmap_loss": 1.986021876335144, "train/loss": 29.915931701660156, "train/grad_norm": 18.597225189208984, "learning_rate": 7.146666666666666e-05, "momentum": 0.9, "_runtime": 97.09008526802063, "_timestamp": 1676688678.0678349, "_step": 19}
{"train/det_cls.d0_loss": 0.7420966625213623, "train/det_cls.d1_loss": 0.6577200293540955, "train/det_cls.d2_loss": 0.6280867457389832, "train/det_cls.d3_loss": 0.6087902784347534, "train/det_cls.d4_loss": 0.6027801036834717, "train/det_cls.d5_loss": 0.5895439386367798, "train/det_reg.d0_loss": 3.170880079269409, "train/det_reg.d1_loss": 2.941701889038086, "train/det_reg.d2_loss": 2.9362447261810303, "train/det_reg.d3_loss": 2.797667980194092, "train/det_reg.d4_loss": 2.8367419242858887, "train/det_reg.d5_loss": 2.9936933517456055, "train/wp.d0_loss": 1.1426844596862793, "train/wp.d1_loss": 1.0620852708816528, "train/wp.d2_loss": 1.043233871459961, "train/wp.d3_loss": 1.0373661518096924, "train/wp.d4_loss": 1.0407261848449707, "train/wp.d5_loss": 1.035797119140625, "train/wp": 1.035797119140625, "train/attnmap_loss": 2.0146243572235107, "train/loss": 29.882465362548828, "train/grad_norm": 20.070417404174805, "learning_rate": 7.173333333333332e-05, "momentum": 0.9, "_runtime": 100.06337141990662, "_timestamp": 1676688681.041121, "_step": 20}
{"train/det_cls.d0_loss": 0.7118086814880371, "train/det_cls.d1_loss": 0.6662094593048096, "train/det_cls.d2_loss": 0.6608872413635254, "train/det_cls.d3_loss": 0.6293405890464783, "train/det_cls.d4_loss": 0.6143602728843689, "train/det_cls.d5_loss": 0.5986440181732178, "train/det_reg.d0_loss": 3.1362757682800293, "train/det_reg.d1_loss": 2.960020065307617, "train/det_reg.d2_loss": 2.9072327613830566, "train/det_reg.d3_loss": 2.7052388191223145, "train/det_reg.d4_loss": 2.8268449306488037, "train/det_reg.d5_loss": 3.0074477195739746, "train/wp.d0_loss": 1.104449987411499, "train/wp.d1_loss": 1.0172432661056519, "train/wp.d2_loss": 1.0083026885986328, "train/wp.d3_loss": 0.9923532009124756, "train/wp.d4_loss": 0.9920259714126587, "train/wp.d5_loss": 0.9920952320098877, "train/wp": 0.9920952320098877, "train/attnmap_loss": 1.0618817806243896, "train/loss": 28.592660903930664, "train/grad_norm": 19.936565399169922, "learning_rate": 7.2e-05, "momentum": 0.9, "_runtime": 103.49279737472534, "_timestamp": 1676688684.470547, "_step": 21}
{"train/det_cls.d0_loss": 0.6841769218444824, "train/det_cls.d1_loss": 0.6502307653427124, "train/det_cls.d2_loss": 0.6420373916625977, "train/det_cls.d3_loss": 0.6352970600128174, "train/det_cls.d4_loss": 0.609511137008667, "train/det_cls.d5_loss": 0.5893368721008301, "train/det_reg.d0_loss": 3.152894973754883, "train/det_reg.d1_loss": 2.9536707401275635, "train/det_reg.d2_loss": 2.981724739074707, "train/det_reg.d3_loss": 2.8781023025512695, "train/det_reg.d4_loss": 2.970177173614502, "train/det_reg.d5_loss": 3.151182174682617, "train/wp.d0_loss": 1.050243616104126, "train/wp.d1_loss": 0.9843999147415161, "train/wp.d2_loss": 0.9820975065231323, "train/wp.d3_loss": 0.9871947765350342, "train/wp.d4_loss": 0.9526304006576538, "train/wp.d5_loss": 0.9834409952163696, "train/wp": 0.9834409952163696, "train/attnmap_loss": 1.7256457805633545, "train/loss": 29.563995361328125, "train/grad_norm": 19.09621238708496, "learning_rate": 7.226666666666666e-05, "momentum": 0.9, "_runtime": 106.83243036270142, "_timestamp": 1676688687.81018, "_step": 22}
{"train/det_cls.d0_loss": 0.6499946117401123, "train/det_cls.d1_loss": 0.6292482614517212, "train/det_cls.d2_loss": 0.6281237006187439, "train/det_cls.d3_loss": 0.6177824139595032, "train/det_cls.d4_loss": 0.5997399091720581, "train/det_cls.d5_loss": 0.5790707468986511, "train/det_reg.d0_loss": 3.096463918685913, "train/det_reg.d1_loss": 2.890359401702881, "train/det_reg.d2_loss": 2.8969030380249023, "train/det_reg.d3_loss": 2.7228024005889893, "train/det_reg.d4_loss": 2.9278407096862793, "train/det_reg.d5_loss": 3.0718812942504883, "train/wp.d0_loss": 1.3637160062789917, "train/wp.d1_loss": 1.3352456092834473, "train/wp.d2_loss": 1.325096845626831, "train/wp.d3_loss": 1.3127195835113525, "train/wp.d4_loss": 1.2395529747009277, "train/wp.d5_loss": 1.3149627447128296, "train/wp": 1.3149627447128296, "train/attnmap_loss": 1.4505223035812378, "train/loss": 30.652027130126953, "train/grad_norm": 33.1361198425293, "learning_rate": 7.253333333333333e-05, "momentum": 0.9, "_runtime": 110.0453748703003, "_timestamp": 1676688691.0231245, "_step": 23}
{"train/det_cls.d0_loss": 0.6385999917984009, "train/det_cls.d1_loss": 0.6839473843574524, "train/det_cls.d2_loss": 0.6760327816009521, "train/det_cls.d3_loss": 0.6648722290992737, "train/det_cls.d4_loss": 0.6486619710922241, "train/det_cls.d5_loss": 0.6404311656951904, "train/det_reg.d0_loss": 3.0094845294952393, "train/det_reg.d1_loss": 2.8688910007476807, "train/det_reg.d2_loss": 2.852234363555908, "train/det_reg.d3_loss": 2.7102088928222656, "train/det_reg.d4_loss": 2.930295944213867, "train/det_reg.d5_loss": 3.0718674659729004, "train/wp.d0_loss": 1.3439688682556152, "train/wp.d1_loss": 1.3719297647476196, "train/wp.d2_loss": 1.3795123100280762, "train/wp.d3_loss": 1.3004181385040283, "train/wp.d4_loss": 1.2629077434539795, "train/wp.d5_loss": 1.3360838890075684, "train/wp": 1.3360838890075684, "train/attnmap_loss": 2.1750125885009766, "train/loss": 31.56536293029785, "train/grad_norm": 38.76310348510742, "learning_rate": 7.280000000000001e-05, "momentum": 0.9, "_runtime": 113.23066234588623, "_timestamp": 1676688694.208412, "_step": 24}
{"train/det_cls.d0_loss": 0.5941682457923889, "train/det_cls.d1_loss": 0.6136811375617981, "train/det_cls.d2_loss": 0.6053814888000488, "train/det_cls.d3_loss": 0.6067750453948975, "train/det_cls.d4_loss": 0.5935713052749634, "train/det_cls.d5_loss": 0.583641529083252, "train/det_reg.d0_loss": 2.9710612297058105, "train/det_reg.d1_loss": 2.72041654586792, "train/det_reg.d2_loss": 2.754621982574463, "train/det_reg.d3_loss": 2.673872709274292, "train/det_reg.d4_loss": 2.8405954837799072, "train/det_reg.d5_loss": 2.9283945560455322, "train/wp.d0_loss": 1.3003315925598145, "train/wp.d1_loss": 1.2984908819198608, "train/wp.d2_loss": 1.2912580966949463, "train/wp.d3_loss": 1.2567169666290283, "train/wp.d4_loss": 1.2231018543243408, "train/wp.d5_loss": 1.2361412048339844, "train/wp": 1.2361412048339844, "train/attnmap_loss": 1.7281017303466797, "train/loss": 29.820323944091797, "train/grad_norm": 28.240283966064453, "learning_rate": 7.306666666666666e-05, "momentum": 0.9, "_runtime": 116.75709772109985, "_timestamp": 1676688697.7348473, "_step": 25}
{"train/det_cls.d0_loss": 0.5992251634597778, "train/det_cls.d1_loss": 0.6360511183738708, "train/det_cls.d2_loss": 0.6182647943496704, "train/det_cls.d3_loss": 0.6175145506858826, "train/det_cls.d4_loss": 0.6136198043823242, "train/det_cls.d5_loss": 0.6169272661209106, "train/det_reg.d0_loss": 3.0894875526428223, "train/det_reg.d1_loss": 2.8555026054382324, "train/det_reg.d2_loss": 2.8387258052825928, "train/det_reg.d3_loss": 2.7680740356445312, "train/det_reg.d4_loss": 2.9598212242126465, "train/det_reg.d5_loss": 2.993654489517212, "train/wp.d0_loss": 1.3405370712280273, "train/wp.d1_loss": 1.2931833267211914, "train/wp.d2_loss": 1.2867085933685303, "train/wp.d3_loss": 1.2521398067474365, "train/wp.d4_loss": 1.2501178979873657, "train/wp.d5_loss": 1.2527639865875244, "train/wp": 1.2527639865875244, "train/attnmap_loss": 1.2994731664657593, "train/loss": 30.181793212890625, "train/grad_norm": 27.5705509185791, "learning_rate": 7.333333333333332e-05, "momentum": 0.9, "_runtime": 120.0908272266388, "_timestamp": 1676688701.0685768, "_step": 26}
{"train/det_cls.d0_loss": 0.6038184762001038, "train/det_cls.d1_loss": 0.6323331594467163, "train/det_cls.d2_loss": 0.6123510003089905, "train/det_cls.d3_loss": 0.615028977394104, "train/det_cls.d4_loss": 0.6131606101989746, "train/det_cls.d5_loss": 0.6259540319442749, "train/det_reg.d0_loss": 2.933720827102661, "train/det_reg.d1_loss": 2.732595205307007, "train/det_reg.d2_loss": 2.7220535278320312, "train/det_reg.d3_loss": 2.638376474380493, "train/det_reg.d4_loss": 2.767871856689453, "train/det_reg.d5_loss": 2.7610437870025635, "train/wp.d0_loss": 1.2559986114501953, "train/wp.d1_loss": 1.2129807472229004, "train/wp.d2_loss": 1.1964750289916992, "train/wp.d3_loss": 1.1743290424346924, "train/wp.d4_loss": 1.202135682106018, "train/wp.d5_loss": 1.1891292333602905, "train/wp": 1.1891292333602905, "train/attnmap_loss": 1.5119903087615967, "train/loss": 29.001346588134766, "train/grad_norm": 25.03270721435547, "learning_rate": 7.36e-05, "momentum": 0.9, "_runtime": 123.3031268119812, "_timestamp": 1676688704.2808764, "_step": 27}
{"train/det_cls.d0_loss": 0.5767518877983093, "train/det_cls.d1_loss": 0.630357563495636, "train/det_cls.d2_loss": 0.6171978712081909, "train/det_cls.d3_loss": 0.6280957460403442, "train/det_cls.d4_loss": 0.6154389381408691, "train/det_cls.d5_loss": 0.6247373223304749, "train/det_reg.d0_loss": 2.954887628555298, "train/det_reg.d1_loss": 2.702087163925171, "train/det_reg.d2_loss": 2.72664475440979, "train/det_reg.d3_loss": 2.689973831176758, "train/det_reg.d4_loss": 2.8016748428344727, "train/det_reg.d5_loss": 2.7981531620025635, "train/wp.d0_loss": 1.3292412757873535, "train/wp.d1_loss": 1.2941317558288574, "train/wp.d2_loss": 1.2809391021728516, "train/wp.d3_loss": 1.271754503250122, "train/wp.d4_loss": 1.2481234073638916, "train/wp.d5_loss": 1.2945383787155151, "train/wp": 1.2945383787155151, "train/attnmap_loss": 1.8308818340301514, "train/loss": 29.915611267089844, "train/grad_norm": 28.18915557861328, "learning_rate": 7.386666666666666e-05, "momentum": 0.9, "_runtime": 126.34227967262268, "_timestamp": 1676688707.3200293, "_step": 28}
{"train/det_cls.d0_loss": 0.5726034641265869, "train/det_cls.d1_loss": 0.5977842807769775, "train/det_cls.d2_loss": 0.6007108688354492, "train/det_cls.d3_loss": 0.6071557998657227, "train/det_cls.d4_loss": 0.5955509543418884, "train/det_cls.d5_loss": 0.6023040413856506, "train/det_reg.d0_loss": 2.986337900161743, "train/det_reg.d1_loss": 2.756321668624878, "train/det_reg.d2_loss": 2.6547181606292725, "train/det_reg.d3_loss": 2.5873146057128906, "train/det_reg.d4_loss": 2.6170225143432617, "train/det_reg.d5_loss": 2.710310459136963, "train/wp.d0_loss": 1.1422204971313477, "train/wp.d1_loss": 1.127368688583374, "train/wp.d2_loss": 1.1349031925201416, "train/wp.d3_loss": 1.0995365381240845, "train/wp.d4_loss": 1.0633623600006104, "train/wp.d5_loss": 1.1000680923461914, "train/wp": 1.1000680923461914, "train/attnmap_loss": 1.3768129348754883, "train/loss": 27.932405471801758, "train/grad_norm": 23.38924217224121, "learning_rate": 7.413333333333332e-05, "momentum": 0.9, "_runtime": 129.80759572982788, "_timestamp": 1676688710.7853453, "_step": 29}
{"train/det_cls.d0_loss": 0.592024564743042, "train/det_cls.d1_loss": 0.6262397170066833, "train/det_cls.d2_loss": 0.6271927356719971, "train/det_cls.d3_loss": 0.6278254985809326, "train/det_cls.d4_loss": 0.6216421127319336, "train/det_cls.d5_loss": 0.6321816444396973, "train/det_reg.d0_loss": 2.9470438957214355, "train/det_reg.d1_loss": 2.763246536254883, "train/det_reg.d2_loss": 2.6991448402404785, "train/det_reg.d3_loss": 2.6402828693389893, "train/det_reg.d4_loss": 2.682197332382202, "train/det_reg.d5_loss": 2.7532787322998047, "train/wp.d0_loss": 1.1791667938232422, "train/wp.d1_loss": 1.2053295373916626, "train/wp.d2_loss": 1.1847277879714966, "train/wp.d3_loss": 1.1298019886016846, "train/wp.d4_loss": 1.1136903762817383, "train/wp.d5_loss": 1.1446499824523926, "train/wp": 1.1446499824523926, "train/attnmap_loss": 2.0330467224121094, "train/loss": 29.202714920043945, "train/grad_norm": 30.957660675048828, "learning_rate": 7.44e-05, "momentum": 0.9, "_runtime": 133.18118357658386, "_timestamp": 1676688714.1589332, "_step": 30}
{"train/det_cls.d0_loss": 0.6298639178276062, "train/det_cls.d1_loss": 0.6493011713027954, "train/det_cls.d2_loss": 0.6485540270805359, "train/det_cls.d3_loss": 0.6391260623931885, "train/det_cls.d4_loss": 0.6357675790786743, "train/det_cls.d5_loss": 0.6469594836235046, "train/det_reg.d0_loss": 2.7610321044921875, "train/det_reg.d1_loss": 2.644172191619873, "train/det_reg.d2_loss": 2.6268093585968018, "train/det_reg.d3_loss": 2.5433199405670166, "train/det_reg.d4_loss": 2.5622565746307373, "train/det_reg.d5_loss": 2.735121726989746, "train/wp.d0_loss": 0.9911819696426392, "train/wp.d1_loss": 1.0341789722442627, "train/wp.d2_loss": 1.0241823196411133, "train/wp.d3_loss": 0.9440865516662598, "train/wp.d4_loss": 0.9434899091720581, "train/wp.d5_loss": 0.9491853713989258, "train/wp": 0.9491853713989258, "train/attnmap_loss": 1.7539904117584229, "train/loss": 27.362579345703125, "train/grad_norm": 36.364871978759766, "learning_rate": 7.466666666666666e-05, "momentum": 0.9, "_runtime": 136.31218075752258, "_timestamp": 1676688717.2899303, "_step": 31}
{"train/det_cls.d0_loss": 0.5997801423072815, "train/det_cls.d1_loss": 0.6292661428451538, "train/det_cls.d2_loss": 0.6322988271713257, "train/det_cls.d3_loss": 0.6233868598937988, "train/det_cls.d4_loss": 0.6213929653167725, "train/det_cls.d5_loss": 0.6228597164154053, "train/det_reg.d0_loss": 2.7503440380096436, "train/det_reg.d1_loss": 2.6147727966308594, "train/det_reg.d2_loss": 2.6377692222595215, "train/det_reg.d3_loss": 2.574887275695801, "train/det_reg.d4_loss": 2.5983991622924805, "train/det_reg.d5_loss": 2.7642974853515625, "train/wp.d0_loss": 1.0337860584259033, "train/wp.d1_loss": 1.0502794981002808, "train/wp.d2_loss": 1.0302549600601196, "train/wp.d3_loss": 0.9913514852523804, "train/wp.d4_loss": 0.9914373755455017, "train/wp.d5_loss": 0.9895464777946472, "train/wp": 0.9895464777946472, "train/attnmap_loss": 1.1084595918655396, "train/loss": 26.86457061767578, "train/grad_norm": 16.433839797973633, "learning_rate": 7.493333333333332e-05, "momentum": 0.9, "_runtime": 139.31282687187195, "_timestamp": 1676688720.2905765, "_step": 32}
{"train/det_cls.d0_loss": 0.5638441443443298, "train/det_cls.d1_loss": 0.5927361249923706, "train/det_cls.d2_loss": 0.6029918193817139, "train/det_cls.d3_loss": 0.5953731536865234, "train/det_cls.d4_loss": 0.6016234159469604, "train/det_cls.d5_loss": 0.6062965393066406, "train/det_reg.d0_loss": 2.822460174560547, "train/det_reg.d1_loss": 2.7269179821014404, "train/det_reg.d2_loss": 2.646965980529785, "train/det_reg.d3_loss": 2.5568671226501465, "train/det_reg.d4_loss": 2.626833438873291, "train/det_reg.d5_loss": 2.9036428928375244, "train/wp.d0_loss": 0.9690693616867065, "train/wp.d1_loss": 0.9585739374160767, "train/wp.d2_loss": 0.9303654432296753, "train/wp.d3_loss": 0.9310430288314819, "train/wp.d4_loss": 0.9209299087524414, "train/wp.d5_loss": 0.9248663187026978, "train/wp": 0.9248663187026978, "train/attnmap_loss": 1.1241101026535034, "train/loss": 26.605510711669922, "train/grad_norm": 16.628690719604492, "learning_rate": 7.52e-05, "momentum": 0.9, "_runtime": 142.7820382118225, "_timestamp": 1676688723.7597878, "_step": 33}
