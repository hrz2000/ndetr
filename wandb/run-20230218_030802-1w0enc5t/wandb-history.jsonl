{"train/det_cls.d0_loss": 2.4270453453063965, "train/det_cls.d1_loss": 2.4229347705841064, "train/det_cls.d2_loss": 2.308955192565918, "train/det_cls.d3_loss": 2.4713590145111084, "train/det_cls.d4_loss": 2.3953022956848145, "train/det_cls.d5_loss": 2.5619149208068848, "train/det_reg.d0_loss": 3.9584414958953857, "train/det_reg.d1_loss": 3.884732484817505, "train/det_reg.d2_loss": 3.8897969722747803, "train/det_reg.d3_loss": 3.8414530754089355, "train/det_reg.d4_loss": 3.8480796813964844, "train/det_reg.d5_loss": 3.9146437644958496, "train/wp.d0_loss": 2.2086501121520996, "train/wp.d1_loss": 2.320781707763672, "train/wp.d2_loss": 2.3344123363494873, "train/wp.d3_loss": 2.3090295791625977, "train/wp.d4_loss": 2.2513489723205566, "train/wp.d5_loss": 2.0670580863952637, "train/wp": 2.0670580863952637, "train/attnmap_loss": 1.9436105489730835, "train/loss": 53.359554290771484, "train/grad_norm": 73.48120880126953, "learning_rate": 6.666666666666666e-05, "momentum": 0.9, "_runtime": 32.64084267616272, "_timestamp": 1676689695.4479477, "_step": 1}
{"train/det_cls.d0_loss": 2.2862534523010254, "train/det_cls.d1_loss": 2.2599799633026123, "train/det_cls.d2_loss": 2.125769853591919, "train/det_cls.d3_loss": 2.2679481506347656, "train/det_cls.d4_loss": 2.211651086807251, "train/det_cls.d5_loss": 2.32315731048584, "train/det_reg.d0_loss": 3.9707374572753906, "train/det_reg.d1_loss": 3.7831342220306396, "train/det_reg.d2_loss": 3.732851505279541, "train/det_reg.d3_loss": 3.5961947441101074, "train/det_reg.d4_loss": 3.5606207847595215, "train/det_reg.d5_loss": 3.604487419128418, "train/wp.d0_loss": 2.096928119659424, "train/wp.d1_loss": 2.11645770072937, "train/wp.d2_loss": 2.004561424255371, "train/wp.d3_loss": 1.9677003622055054, "train/wp.d4_loss": 1.8554730415344238, "train/wp.d5_loss": 1.7396416664123535, "train/wp": 1.7396416664123535, "train/attnmap_loss": 1.723517656326294, "train/loss": 49.22706604003906, "train/grad_norm": 67.78762817382812, "learning_rate": 6.693333333333331e-05, "momentum": 0.9, "_runtime": 36.86771607398987, "_timestamp": 1676689699.6748211, "_step": 2}
{"train/det_cls.d0_loss": 2.141420841217041, "train/det_cls.d1_loss": 2.1337497234344482, "train/det_cls.d2_loss": 1.9917887449264526, "train/det_cls.d3_loss": 2.156327962875366, "train/det_cls.d4_loss": 2.073223114013672, "train/det_cls.d5_loss": 2.135000228881836, "train/det_reg.d0_loss": 3.754734516143799, "train/det_reg.d1_loss": 3.567422389984131, "train/det_reg.d2_loss": 3.532409191131592, "train/det_reg.d3_loss": 3.4579336643218994, "train/det_reg.d4_loss": 3.434081792831421, "train/det_reg.d5_loss": 3.4551520347595215, "train/wp.d0_loss": 1.9895130395889282, "train/wp.d1_loss": 1.9322816133499146, "train/wp.d2_loss": 1.7493338584899902, "train/wp.d3_loss": 1.6839280128479004, "train/wp.d4_loss": 1.5230225324630737, "train/wp.d5_loss": 1.4665604829788208, "train/wp": 1.4665604829788208, "train/attnmap_loss": 1.9290204048156738, "train/loss": 46.106903076171875, "train/grad_norm": 59.56019973754883, "learning_rate": 6.72e-05, "momentum": 0.9, "_runtime": 39.73820948600769, "_timestamp": 1676689702.5453146, "_step": 3}
{"train/det_cls.d0_loss": 2.0187926292419434, "train/det_cls.d1_loss": 1.9467241764068604, "train/det_cls.d2_loss": 1.8166240453720093, "train/det_cls.d3_loss": 1.9401532411575317, "train/det_cls.d4_loss": 1.9421385526657104, "train/det_cls.d5_loss": 1.9671069383621216, "train/det_reg.d0_loss": 3.725553512573242, "train/det_reg.d1_loss": 3.614858627319336, "train/det_reg.d2_loss": 3.601881980895996, "train/det_reg.d3_loss": 3.5012054443359375, "train/det_reg.d4_loss": 3.470383882522583, "train/det_reg.d5_loss": 3.5028717517852783, "train/wp.d0_loss": 1.9310312271118164, "train/wp.d1_loss": 1.8211519718170166, "train/wp.d2_loss": 1.6041439771652222, "train/wp.d3_loss": 1.5727715492248535, "train/wp.d4_loss": 1.5132032632827759, "train/wp.d5_loss": 1.4999209642410278, "train/wp": 1.4999209642410278, "train/attnmap_loss": 1.461885690689087, "train/loss": 44.45240020751953, "train/grad_norm": 42.73308563232422, "learning_rate": 6.746666666666666e-05, "momentum": 0.9, "_runtime": 42.72520422935486, "_timestamp": 1676689705.5323093, "_step": 4}
{"train/det_cls.d0_loss": 1.8844244480133057, "train/det_cls.d1_loss": 1.8105748891830444, "train/det_cls.d2_loss": 1.688617467880249, "train/det_cls.d3_loss": 1.7582337856292725, "train/det_cls.d4_loss": 1.7898468971252441, "train/det_cls.d5_loss": 1.7958753108978271, "train/det_reg.d0_loss": 3.7293701171875, "train/det_reg.d1_loss": 3.524413585662842, "train/det_reg.d2_loss": 3.4474616050720215, "train/det_reg.d3_loss": 3.347543478012085, "train/det_reg.d4_loss": 3.3254542350769043, "train/det_reg.d5_loss": 3.345107078552246, "train/wp.d0_loss": 1.665661096572876, "train/wp.d1_loss": 1.5300052165985107, "train/wp.d2_loss": 1.3601573705673218, "train/wp.d3_loss": 1.361271858215332, "train/wp.d4_loss": 1.3658063411712646, "train/wp.d5_loss": 1.3634852170944214, "train/wp": 1.3634852170944214, "train/attnmap_loss": 1.4948687553405762, "train/loss": 41.58818054199219, "train/grad_norm": 40.04326248168945, "learning_rate": 6.773333333333332e-05, "momentum": 0.9, "_runtime": 46.12837791442871, "_timestamp": 1676689708.935483, "_step": 5}
{"train/det_cls.d0_loss": 1.7800629138946533, "train/det_cls.d1_loss": 1.6925866603851318, "train/det_cls.d2_loss": 1.576529622077942, "train/det_cls.d3_loss": 1.6055829524993896, "train/det_cls.d4_loss": 1.6047381162643433, "train/det_cls.d5_loss": 1.639636516571045, "train/det_reg.d0_loss": 3.553332805633545, "train/det_reg.d1_loss": 3.450951099395752, "train/det_reg.d2_loss": 3.3883743286132812, "train/det_reg.d3_loss": 3.2417778968811035, "train/det_reg.d4_loss": 3.2264797687530518, "train/det_reg.d5_loss": 3.1990842819213867, "train/wp.d0_loss": 1.4686076641082764, "train/wp.d1_loss": 1.3056271076202393, "train/wp.d2_loss": 1.2509758472442627, "train/wp.d3_loss": 1.2450282573699951, "train/wp.d4_loss": 1.2595317363739014, "train/wp.d5_loss": 1.2563543319702148, "train/wp": 1.2563543319702148, "train/attnmap_loss": 1.3787219524383545, "train/loss": 39.123985290527344, "train/grad_norm": 36.43692398071289, "learning_rate": 6.8e-05, "momentum": 0.9, "_runtime": 49.45157313346863, "_timestamp": 1676689712.2586782, "_step": 6}
{"train/det_cls.d0_loss": 1.6118288040161133, "train/det_cls.d1_loss": 1.6298556327819824, "train/det_cls.d2_loss": 1.4577604532241821, "train/det_cls.d3_loss": 1.4863252639770508, "train/det_cls.d4_loss": 1.4191560745239258, "train/det_cls.d5_loss": 1.496565341949463, "train/det_reg.d0_loss": 3.4388222694396973, "train/det_reg.d1_loss": 3.446870803833008, "train/det_reg.d2_loss": 3.4118311405181885, "train/det_reg.d3_loss": 3.2976725101470947, "train/det_reg.d4_loss": 3.2934393882751465, "train/det_reg.d5_loss": 3.2211406230926514, "train/wp.d0_loss": 1.5847927331924438, "train/wp.d1_loss": 1.4382109642028809, "train/wp.d2_loss": 1.3707746267318726, "train/wp.d3_loss": 1.3437989950180054, "train/wp.d4_loss": 1.2951714992523193, "train/wp.d5_loss": 1.2549935579299927, "train/wp": 1.2549935579299927, "train/attnmap_loss": 1.178192377090454, "train/loss": 38.67720031738281, "train/grad_norm": 40.05208969116211, "learning_rate": 6.826666666666665e-05, "momentum": 0.9, "_runtime": 52.27250838279724, "_timestamp": 1676689715.0796134, "_step": 7}
{"train/det_cls.d0_loss": 1.554809808731079, "train/det_cls.d1_loss": 1.4598453044891357, "train/det_cls.d2_loss": 1.3268637657165527, "train/det_cls.d3_loss": 1.3259084224700928, "train/det_cls.d4_loss": 1.3457071781158447, "train/det_cls.d5_loss": 1.4192696809768677, "train/det_reg.d0_loss": 3.5435500144958496, "train/det_reg.d1_loss": 3.418253183364868, "train/det_reg.d2_loss": 3.3394646644592285, "train/det_reg.d3_loss": 3.206148386001587, "train/det_reg.d4_loss": 3.1623287200927734, "train/det_reg.d5_loss": 3.1007401943206787, "train/wp.d0_loss": 1.3704451322555542, "train/wp.d1_loss": 1.2575724124908447, "train/wp.d2_loss": 1.2587131261825562, "train/wp.d3_loss": 1.2018945217132568, "train/wp.d4_loss": 1.1627494096755981, "train/wp.d5_loss": 1.1486374139785767, "train/wp": 1.1486374139785767, "train/attnmap_loss": 1.5605980157852173, "train/loss": 37.16349792480469, "train/grad_norm": 31.305185317993164, "learning_rate": 6.853333333333331e-05, "momentum": 0.9, "_runtime": 55.226292848587036, "_timestamp": 1676689718.033398, "_step": 8}
{"train/det_cls.d0_loss": 1.4636414051055908, "train/det_cls.d1_loss": 1.3771897554397583, "train/det_cls.d2_loss": 1.216217279434204, "train/det_cls.d3_loss": 1.2152317762374878, "train/det_cls.d4_loss": 1.2051942348480225, "train/det_cls.d5_loss": 1.3010882139205933, "train/det_reg.d0_loss": 3.3854053020477295, "train/det_reg.d1_loss": 3.2458090782165527, "train/det_reg.d2_loss": 3.2113685607910156, "train/det_reg.d3_loss": 3.135908842086792, "train/det_reg.d4_loss": 3.0886640548706055, "train/det_reg.d5_loss": 3.0486087799072266, "train/wp.d0_loss": 1.3469862937927246, "train/wp.d1_loss": 1.2418941259384155, "train/wp.d2_loss": 1.1982077360153198, "train/wp.d3_loss": 1.1471689939498901, "train/wp.d4_loss": 1.0976061820983887, "train/wp.d5_loss": 1.0804753303527832, "train/wp": 1.0804753303527832, "train/attnmap_loss": 1.6302226781845093, "train/loss": 35.63688659667969, "train/grad_norm": 35.262176513671875, "learning_rate": 6.879999999999999e-05, "momentum": 0.9, "_runtime": 58.45114994049072, "_timestamp": 1676689721.258255, "_step": 9}
{"train/det_cls.d0_loss": 1.3664358854293823, "train/det_cls.d1_loss": 1.2828987836837769, "train/det_cls.d2_loss": 1.1213362216949463, "train/det_cls.d3_loss": 1.1126737594604492, "train/det_cls.d4_loss": 1.1073033809661865, "train/det_cls.d5_loss": 1.205635666847229, "train/det_reg.d0_loss": 3.407716751098633, "train/det_reg.d1_loss": 3.2556564807891846, "train/det_reg.d2_loss": 3.190338373184204, "train/det_reg.d3_loss": 3.03361177444458, "train/det_reg.d4_loss": 3.0126688480377197, "train/det_reg.d5_loss": 2.9988534450531006, "train/wp.d0_loss": 1.3489067554473877, "train/wp.d1_loss": 1.246694564819336, "train/wp.d2_loss": 1.1682909727096558, "train/wp.d3_loss": 1.134782314300537, "train/wp.d4_loss": 1.0865728855133057, "train/wp.d5_loss": 1.114621639251709, "train/wp": 1.114621639251709, "train/attnmap_loss": 2.5456840991973877, "train/loss": 35.740684509277344, "train/grad_norm": 33.11094665527344, "learning_rate": 6.906666666666666e-05, "momentum": 0.9, "_runtime": 61.70125651359558, "_timestamp": 1676689724.5083616, "_step": 10}
{"train/det_cls.d0_loss": 1.3020052909851074, "train/det_cls.d1_loss": 1.2005043029785156, "train/det_cls.d2_loss": 1.0272482633590698, "train/det_cls.d3_loss": 1.0362828969955444, "train/det_cls.d4_loss": 1.0269198417663574, "train/det_cls.d5_loss": 1.1063247919082642, "train/det_reg.d0_loss": 3.3894729614257812, "train/det_reg.d1_loss": 3.2734742164611816, "train/det_reg.d2_loss": 3.201345682144165, "train/det_reg.d3_loss": 3.0734305381774902, "train/det_reg.d4_loss": 3.0172042846679688, "train/det_reg.d5_loss": 2.948711395263672, "train/wp.d0_loss": 1.2857545614242554, "train/wp.d1_loss": 1.2038205862045288, "train/wp.d2_loss": 1.1563820838928223, "train/wp.d3_loss": 1.151036024093628, "train/wp.d4_loss": 1.1485583782196045, "train/wp.d5_loss": 1.148279070854187, "train/wp": 1.148279070854187, "train/attnmap_loss": 1.7330656051635742, "train/loss": 34.42982482910156, "train/grad_norm": 30.856380462646484, "learning_rate": 6.933333333333332e-05, "momentum": 0.9, "_runtime": 64.51027345657349, "_timestamp": 1676689727.3173785, "_step": 11}
{"train/det_cls.d0_loss": 1.1942007541656494, "train/det_cls.d1_loss": 1.0971975326538086, "train/det_cls.d2_loss": 0.9216917753219604, "train/det_cls.d3_loss": 0.9526809453964233, "train/det_cls.d4_loss": 0.9300023913383484, "train/det_cls.d5_loss": 1.028619647026062, "train/det_reg.d0_loss": 3.2128703594207764, "train/det_reg.d1_loss": 3.092916965484619, "train/det_reg.d2_loss": 2.9733145236968994, "train/det_reg.d3_loss": 2.9357757568359375, "train/det_reg.d4_loss": 2.8616530895233154, "train/det_reg.d5_loss": 2.8399171829223633, "train/wp.d0_loss": 1.2995781898498535, "train/wp.d1_loss": 1.198988676071167, "train/wp.d2_loss": 1.0767765045166016, "train/wp.d3_loss": 1.1066819429397583, "train/wp.d4_loss": 1.0724132061004639, "train/wp.d5_loss": 1.0680795907974243, "train/wp": 1.0680795907974243, "train/attnmap_loss": 1.696767807006836, "train/loss": 32.56012725830078, "train/grad_norm": 37.227657318115234, "learning_rate": 6.96e-05, "momentum": 0.9, "_runtime": 67.5218596458435, "_timestamp": 1676689730.3289647, "_step": 12}
{"train/det_cls.d0_loss": 1.1285884380340576, "train/det_cls.d1_loss": 1.022963047027588, "train/det_cls.d2_loss": 0.8605186343193054, "train/det_cls.d3_loss": 0.8809638023376465, "train/det_cls.d4_loss": 0.8624101877212524, "train/det_cls.d5_loss": 0.9351403713226318, "train/det_reg.d0_loss": 3.350320816040039, "train/det_reg.d1_loss": 3.182725191116333, "train/det_reg.d2_loss": 3.080605983734131, "train/det_reg.d3_loss": 2.9613969326019287, "train/det_reg.d4_loss": 2.933058977127075, "train/det_reg.d5_loss": 2.9200034141540527, "train/wp.d0_loss": 1.1658804416656494, "train/wp.d1_loss": 1.0772430896759033, "train/wp.d2_loss": 0.9524244070053101, "train/wp.d3_loss": 0.9929543733596802, "train/wp.d4_loss": 0.96413654088974, "train/wp.d5_loss": 0.9589366316795349, "train/wp": 0.9589366316795349, "train/attnmap_loss": 1.2943809032440186, "train/loss": 31.52465057373047, "train/grad_norm": 32.98917770385742, "learning_rate": 6.986666666666665e-05, "momentum": 0.9, "_runtime": 70.91943669319153, "_timestamp": 1676689733.7265418, "_step": 13}
{"train/det_cls.d0_loss": 1.0407806634902954, "train/det_cls.d1_loss": 0.9462230205535889, "train/det_cls.d2_loss": 0.7995678782463074, "train/det_cls.d3_loss": 0.8229802250862122, "train/det_cls.d4_loss": 0.8124659061431885, "train/det_cls.d5_loss": 0.8740079998970032, "train/det_reg.d0_loss": 3.2766759395599365, "train/det_reg.d1_loss": 3.06704044342041, "train/det_reg.d2_loss": 2.9382801055908203, "train/det_reg.d3_loss": 2.919055938720703, "train/det_reg.d4_loss": 2.8900465965270996, "train/det_reg.d5_loss": 2.92124342918396, "train/wp.d0_loss": 1.1848578453063965, "train/wp.d1_loss": 1.124005913734436, "train/wp.d2_loss": 1.0330530405044556, "train/wp.d3_loss": 1.064298152923584, "train/wp.d4_loss": 1.0351369380950928, "train/wp.d5_loss": 1.008293867111206, "train/wp": 1.008293867111206, "train/attnmap_loss": 2.091442823410034, "train/loss": 31.849458694458008, "train/grad_norm": 28.598352432250977, "learning_rate": 7.013333333333332e-05, "momentum": 0.9, "_runtime": 74.11008548736572, "_timestamp": 1676689736.9171906, "_step": 14}
{"train/det_cls.d0_loss": 0.9554029703140259, "train/det_cls.d1_loss": 0.8800325989723206, "train/det_cls.d2_loss": 0.7341539263725281, "train/det_cls.d3_loss": 0.7554544806480408, "train/det_cls.d4_loss": 0.7400076985359192, "train/det_cls.d5_loss": 0.7802232503890991, "train/det_reg.d0_loss": 3.2262887954711914, "train/det_reg.d1_loss": 3.074906349182129, "train/det_reg.d2_loss": 2.982328414916992, "train/det_reg.d3_loss": 2.9094865322113037, "train/det_reg.d4_loss": 2.9158272743225098, "train/det_reg.d5_loss": 2.879861831665039, "train/wp.d0_loss": 1.1613280773162842, "train/wp.d1_loss": 1.0627708435058594, "train/wp.d2_loss": 0.9781410694122314, "train/wp.d3_loss": 1.0181796550750732, "train/wp.d4_loss": 0.9698551893234253, "train/wp.d5_loss": 0.9664673209190369, "train/wp": 0.9664673209190369, "train/attnmap_loss": 1.4336719512939453, "train/loss": 30.424388885498047, "train/grad_norm": 33.29453659057617, "learning_rate": 7.04e-05, "momentum": 0.9, "_runtime": 77.03027272224426, "_timestamp": 1676689739.8373778, "_step": 15}
{"train/det_cls.d0_loss": 0.9106956720352173, "train/det_cls.d1_loss": 0.8158194422721863, "train/det_cls.d2_loss": 0.6870435476303101, "train/det_cls.d3_loss": 0.7058025598526001, "train/det_cls.d4_loss": 0.7028552293777466, "train/det_cls.d5_loss": 0.7303805351257324, "train/det_reg.d0_loss": 3.2204132080078125, "train/det_reg.d1_loss": 3.060850143432617, "train/det_reg.d2_loss": 2.9461557865142822, "train/det_reg.d3_loss": 2.88070011138916, "train/det_reg.d4_loss": 2.8736820220947266, "train/det_reg.d5_loss": 2.858874559402466, "train/wp.d0_loss": 1.1563160419464111, "train/wp.d1_loss": 1.0929354429244995, "train/wp.d2_loss": 1.0315470695495605, "train/wp.d3_loss": 1.0426068305969238, "train/wp.d4_loss": 1.0404636859893799, "train/wp.d5_loss": 1.0456788539886475, "train/wp": 1.0456788539886475, "train/attnmap_loss": 1.3249061107635498, "train/loss": 30.127727508544922, "train/grad_norm": 23.636220932006836, "learning_rate": 7.066666666666666e-05, "momentum": 0.9, "_runtime": 80.1136224269867, "_timestamp": 1676689742.9207275, "_step": 16}
{"train/det_cls.d0_loss": 0.8437535166740417, "train/det_cls.d1_loss": 0.7624140381813049, "train/det_cls.d2_loss": 0.6512649059295654, "train/det_cls.d3_loss": 0.6730027198791504, "train/det_cls.d4_loss": 0.6738920211791992, "train/det_cls.d5_loss": 0.6956547498703003, "train/det_reg.d0_loss": 3.2635631561279297, "train/det_reg.d1_loss": 3.0947842597961426, "train/det_reg.d2_loss": 2.9571003913879395, "train/det_reg.d3_loss": 2.896822452545166, "train/det_reg.d4_loss": 2.8536624908447266, "train/det_reg.d5_loss": 2.8336048126220703, "train/wp.d0_loss": 1.0749354362487793, "train/wp.d1_loss": 1.0288689136505127, "train/wp.d2_loss": 1.023910641670227, "train/wp.d3_loss": 0.9901659488677979, "train/wp.d4_loss": 1.0366445779800415, "train/wp.d5_loss": 1.0214598178863525, "train/wp": 1.0214598178863525, "train/attnmap_loss": 1.7520325183868408, "train/loss": 30.12753677368164, "train/grad_norm": 22.699129104614258, "learning_rate": 7.093333333333331e-05, "momentum": 0.9, "_runtime": 83.32856369018555, "_timestamp": 1676689746.1356688, "_step": 17}
{"train/det_cls.d0_loss": 0.7741436958312988, "train/det_cls.d1_loss": 0.7179998755455017, "train/det_cls.d2_loss": 0.6383376121520996, "train/det_cls.d3_loss": 0.6442288160324097, "train/det_cls.d4_loss": 0.650058388710022, "train/det_cls.d5_loss": 0.6671717762947083, "train/det_reg.d0_loss": 3.158447265625, "train/det_reg.d1_loss": 2.9697682857513428, "train/det_reg.d2_loss": 2.8101561069488525, "train/det_reg.d3_loss": 2.7559168338775635, "train/det_reg.d4_loss": 2.6933138370513916, "train/det_reg.d5_loss": 2.7159271240234375, "train/wp.d0_loss": 1.1033451557159424, "train/wp.d1_loss": 1.0145330429077148, "train/wp.d2_loss": 0.9243640899658203, "train/wp.d3_loss": 0.937883734703064, "train/wp.d4_loss": 0.956344485282898, "train/wp.d5_loss": 0.9852181077003479, "train/wp": 0.9852181077003479, "train/attnmap_loss": 1.5704894065856934, "train/loss": 28.687646865844727, "train/grad_norm": 32.148094177246094, "learning_rate": 7.12e-05, "momentum": 0.9, "_runtime": 86.61165475845337, "_timestamp": 1676689749.4187598, "_step": 18}
{"train/det_cls.d0_loss": 0.7426669597625732, "train/det_cls.d1_loss": 0.6761506795883179, "train/det_cls.d2_loss": 0.6143491268157959, "train/det_cls.d3_loss": 0.626868486404419, "train/det_cls.d4_loss": 0.6315413117408752, "train/det_cls.d5_loss": 0.6446948647499084, "train/det_reg.d0_loss": 3.1953163146972656, "train/det_reg.d1_loss": 2.9602479934692383, "train/det_reg.d2_loss": 2.851285696029663, "train/det_reg.d3_loss": 2.8023364543914795, "train/det_reg.d4_loss": 2.739656686782837, "train/det_reg.d5_loss": 2.8166966438293457, "train/wp.d0_loss": 1.0892219543457031, "train/wp.d1_loss": 1.0427181720733643, "train/wp.d2_loss": 1.0434998273849487, "train/wp.d3_loss": 1.0346533060073853, "train/wp.d4_loss": 1.077607274055481, "train/wp.d5_loss": 1.049203634262085, "train/wp": 1.049203634262085, "train/attnmap_loss": 1.6382675170898438, "train/loss": 29.27698516845703, "train/grad_norm": 17.906024932861328, "learning_rate": 7.146666666666666e-05, "momentum": 0.9, "_runtime": 89.42420506477356, "_timestamp": 1676689752.2313101, "_step": 19}
{"train/det_cls.d0_loss": 0.6971915364265442, "train/det_cls.d1_loss": 0.6404998898506165, "train/det_cls.d2_loss": 0.5950208306312561, "train/det_cls.d3_loss": 0.5961397290229797, "train/det_cls.d4_loss": 0.6159765720367432, "train/det_cls.d5_loss": 0.6250354051589966, "train/det_reg.d0_loss": 3.1816606521606445, "train/det_reg.d1_loss": 3.0031299591064453, "train/det_reg.d2_loss": 2.8977346420288086, "train/det_reg.d3_loss": 2.7918148040771484, "train/det_reg.d4_loss": 2.755229949951172, "train/det_reg.d5_loss": 2.81479811668396, "train/wp.d0_loss": 0.9797424674034119, "train/wp.d1_loss": 0.9149866104125977, "train/wp.d2_loss": 0.9241877794265747, "train/wp.d3_loss": 0.9196130633354187, "train/wp.d4_loss": 0.9323242902755737, "train/wp.d5_loss": 0.9090853333473206, "train/wp": 0.9090853333473206, "train/attnmap_loss": 1.9286705255508423, "train/loss": 28.722841262817383, "train/grad_norm": 16.04790496826172, "learning_rate": 7.173333333333332e-05, "momentum": 0.9, "_runtime": 92.57895493507385, "_timestamp": 1676689755.38606, "_step": 20}
{"train/det_cls.d0_loss": 0.6703775525093079, "train/det_cls.d1_loss": 0.6126340627670288, "train/det_cls.d2_loss": 0.5744612216949463, "train/det_cls.d3_loss": 0.5760772228240967, "train/det_cls.d4_loss": 0.5892394185066223, "train/det_cls.d5_loss": 0.5984199643135071, "train/det_reg.d0_loss": 3.149463415145874, "train/det_reg.d1_loss": 2.9500744342803955, "train/det_reg.d2_loss": 2.8513689041137695, "train/det_reg.d3_loss": 2.777873992919922, "train/det_reg.d4_loss": 2.807263135910034, "train/det_reg.d5_loss": 2.797619581222534, "train/wp.d0_loss": 1.1117234230041504, "train/wp.d1_loss": 1.0969631671905518, "train/wp.d2_loss": 1.1182889938354492, "train/wp.d3_loss": 1.1109719276428223, "train/wp.d4_loss": 1.1211133003234863, "train/wp.d5_loss": 1.0934343338012695, "train/wp": 1.0934343338012695, "train/attnmap_loss": 1.189697265625, "train/loss": 28.79706382751465, "train/grad_norm": 17.13801383972168, "learning_rate": 7.2e-05, "momentum": 0.9, "_runtime": 95.87180161476135, "_timestamp": 1676689758.6789067, "_step": 21}
{"train/det_cls.d0_loss": 0.622816801071167, "train/det_cls.d1_loss": 0.5977898240089417, "train/det_cls.d2_loss": 0.5714473724365234, "train/det_cls.d3_loss": 0.5863562226295471, "train/det_cls.d4_loss": 0.6012744307518005, "train/det_cls.d5_loss": 0.6016703844070435, "train/det_reg.d0_loss": 3.0373988151550293, "train/det_reg.d1_loss": 2.871785879135132, "train/det_reg.d2_loss": 2.784942150115967, "train/det_reg.d3_loss": 2.738708734512329, "train/det_reg.d4_loss": 2.7175755500793457, "train/det_reg.d5_loss": 2.7474653720855713, "train/wp.d0_loss": 0.9843214750289917, "train/wp.d1_loss": 0.9467086791992188, "train/wp.d2_loss": 0.9834386110305786, "train/wp.d3_loss": 0.9459327459335327, "train/wp.d4_loss": 0.9522252082824707, "train/wp.d5_loss": 0.941318154335022, "train/wp": 0.941318154335022, "train/attnmap_loss": 1.5424803495407104, "train/loss": 27.775657653808594, "train/grad_norm": 20.36874008178711, "learning_rate": 7.226666666666666e-05, "momentum": 0.9, "_runtime": 99.50069522857666, "_timestamp": 1676689762.3078003, "_step": 22}
{"train/det_cls.d0_loss": 0.6186522245407104, "train/det_cls.d1_loss": 0.5918245315551758, "train/det_cls.d2_loss": 0.5986106395721436, "train/det_cls.d3_loss": 0.6223341226577759, "train/det_cls.d4_loss": 0.6313310265541077, "train/det_cls.d5_loss": 0.6336668729782104, "train/det_reg.d0_loss": 3.071694850921631, "train/det_reg.d1_loss": 2.876708507537842, "train/det_reg.d2_loss": 2.7681381702423096, "train/det_reg.d3_loss": 2.72377872467041, "train/det_reg.d4_loss": 2.678971767425537, "train/det_reg.d5_loss": 2.628622055053711, "train/wp.d0_loss": 0.9922428727149963, "train/wp.d1_loss": 0.9582086205482483, "train/wp.d2_loss": 0.9434407949447632, "train/wp.d3_loss": 0.9285340309143066, "train/wp.d4_loss": 0.9222633242607117, "train/wp.d5_loss": 0.9304206371307373, "train/wp": 0.9304206371307373, "train/attnmap_loss": 1.317352294921875, "train/loss": 27.436798095703125, "train/grad_norm": 23.928081512451172, "learning_rate": 7.253333333333333e-05, "momentum": 0.9, "_runtime": 102.448655128479, "_timestamp": 1676689765.2557602, "_step": 23}
{"train/det_cls.d0_loss": 0.6062263250350952, "train/det_cls.d1_loss": 0.5781755447387695, "train/det_cls.d2_loss": 0.6056456565856934, "train/det_cls.d3_loss": 0.628134548664093, "train/det_cls.d4_loss": 0.6429862380027771, "train/det_cls.d5_loss": 0.6414960622787476, "train/det_reg.d0_loss": 3.044079065322876, "train/det_reg.d1_loss": 2.9177794456481934, "train/det_reg.d2_loss": 2.826852321624756, "train/det_reg.d3_loss": 2.782064199447632, "train/det_reg.d4_loss": 2.7291715145111084, "train/det_reg.d5_loss": 2.6928038597106934, "train/wp.d0_loss": 0.963028073310852, "train/wp.d1_loss": 0.9291994571685791, "train/wp.d2_loss": 0.9396882057189941, "train/wp.d3_loss": 0.9229387044906616, "train/wp.d4_loss": 0.9329678416252136, "train/wp.d5_loss": 0.9279850721359253, "train/wp": 0.9279850721359253, "train/attnmap_loss": 2.0034689903259277, "train/loss": 28.3146915435791, "train/grad_norm": 15.683547973632812, "learning_rate": 7.280000000000001e-05, "momentum": 0.9, "_runtime": 105.51095199584961, "_timestamp": 1676689768.318057, "_step": 24}
{"train/det_cls.d0_loss": 0.5870801210403442, "train/det_cls.d1_loss": 0.5740178823471069, "train/det_cls.d2_loss": 0.6004617214202881, "train/det_cls.d3_loss": 0.6214399337768555, "train/det_cls.d4_loss": 0.6290997862815857, "train/det_cls.d5_loss": 0.6321954727172852, "train/det_reg.d0_loss": 3.050595283508301, "train/det_reg.d1_loss": 2.9047365188598633, "train/det_reg.d2_loss": 2.802828550338745, "train/det_reg.d3_loss": 2.757610559463501, "train/det_reg.d4_loss": 2.769775390625, "train/det_reg.d5_loss": 2.755488395690918, "train/wp.d0_loss": 1.0328634977340698, "train/wp.d1_loss": 1.003585934638977, "train/wp.d2_loss": 1.0163047313690186, "train/wp.d3_loss": 1.0093584060668945, "train/wp.d4_loss": 0.996436595916748, "train/wp.d5_loss": 0.9983499050140381, "train/wp": 0.9983499050140381, "train/attnmap_loss": 1.6207454204559326, "train/loss": 28.362974166870117, "train/grad_norm": 15.618417739868164, "learning_rate": 7.306666666666666e-05, "momentum": 0.9, "_runtime": 109.06556463241577, "_timestamp": 1676689771.8726697, "_step": 25}
{"train/det_cls.d0_loss": 0.5835655927658081, "train/det_cls.d1_loss": 0.5894661545753479, "train/det_cls.d2_loss": 0.6337826251983643, "train/det_cls.d3_loss": 0.6536582708358765, "train/det_cls.d4_loss": 0.6610068082809448, "train/det_cls.d5_loss": 0.658578097820282, "train/det_reg.d0_loss": 3.0108766555786133, "train/det_reg.d1_loss": 2.871464252471924, "train/det_reg.d2_loss": 2.7258403301239014, "train/det_reg.d3_loss": 2.682300329208374, "train/det_reg.d4_loss": 2.6650948524475098, "train/det_reg.d5_loss": 2.6861495971679688, "train/wp.d0_loss": 0.9692472815513611, "train/wp.d1_loss": 0.9310628175735474, "train/wp.d2_loss": 0.9376196265220642, "train/wp.d3_loss": 0.9311766028404236, "train/wp.d4_loss": 0.9292547702789307, "train/wp.d5_loss": 0.9462124109268188, "train/wp": 0.9462124109268188, "train/attnmap_loss": 1.996000051498413, "train/loss": 28.06235694885254, "train/grad_norm": 17.294342041015625, "learning_rate": 7.333333333333332e-05, "momentum": 0.9, "_runtime": 112.40779519081116, "_timestamp": 1676689775.2149003, "_step": 26}
{"train/det_cls.d0_loss": 0.5863415002822876, "train/det_cls.d1_loss": 0.5945132970809937, "train/det_cls.d2_loss": 0.6213419437408447, "train/det_cls.d3_loss": 0.6460382342338562, "train/det_cls.d4_loss": 0.6531797051429749, "train/det_cls.d5_loss": 0.6409040689468384, "train/det_reg.d0_loss": 2.950883388519287, "train/det_reg.d1_loss": 2.7923827171325684, "train/det_reg.d2_loss": 2.6893670558929443, "train/det_reg.d3_loss": 2.6275806427001953, "train/det_reg.d4_loss": 2.595111846923828, "train/det_reg.d5_loss": 2.601271152496338, "train/wp.d0_loss": 1.0484780073165894, "train/wp.d1_loss": 1.0352699756622314, "train/wp.d2_loss": 1.0747824907302856, "train/wp.d3_loss": 1.044690728187561, "train/wp.d4_loss": 1.0250707864761353, "train/wp.d5_loss": 1.0333083868026733, "train/wp": 1.0333083868026733, "train/attnmap_loss": 1.8176788091659546, "train/loss": 28.078197479248047, "train/grad_norm": 17.499574661254883, "learning_rate": 7.36e-05, "momentum": 0.9, "_runtime": 115.24163508415222, "_timestamp": 1676689778.0487401, "_step": 27}
{"train/det_cls.d0_loss": 0.5625587701797485, "train/det_cls.d1_loss": 0.5788924694061279, "train/det_cls.d2_loss": 0.6032180786132812, "train/det_cls.d3_loss": 0.6202424764633179, "train/det_cls.d4_loss": 0.6249392628669739, "train/det_cls.d5_loss": 0.6168394088745117, "train/det_reg.d0_loss": 2.9523229598999023, "train/det_reg.d1_loss": 2.8193552494049072, "train/det_reg.d2_loss": 2.742868185043335, "train/det_reg.d3_loss": 2.6351122856140137, "train/det_reg.d4_loss": 2.6479454040527344, "train/det_reg.d5_loss": 2.649923324584961, "train/wp.d0_loss": 0.9543149471282959, "train/wp.d1_loss": 0.9357283115386963, "train/wp.d2_loss": 0.9690865278244019, "train/wp.d3_loss": 0.9479851722717285, "train/wp.d4_loss": 0.9436360001564026, "train/wp.d5_loss": 0.9461222887039185, "train/wp": 0.9461222887039185, "train/attnmap_loss": 2.3048336505889893, "train/loss": 28.055925369262695, "train/grad_norm": 14.911638259887695, "learning_rate": 7.386666666666666e-05, "momentum": 0.9, "_runtime": 118.37023520469666, "_timestamp": 1676689781.1773403, "_step": 28}
{"train/det_cls.d0_loss": 0.5543930530548096, "train/det_cls.d1_loss": 0.5794206857681274, "train/det_cls.d2_loss": 0.595138669013977, "train/det_cls.d3_loss": 0.6112353205680847, "train/det_cls.d4_loss": 0.609489381313324, "train/det_cls.d5_loss": 0.6024411916732788, "train/det_reg.d0_loss": 2.977674961090088, "train/det_reg.d1_loss": 2.769791841506958, "train/det_reg.d2_loss": 2.685229778289795, "train/det_reg.d3_loss": 2.651764392852783, "train/det_reg.d4_loss": 2.736880302429199, "train/det_reg.d5_loss": 2.6888790130615234, "train/wp.d0_loss": 0.9710299968719482, "train/wp.d1_loss": 0.9559949636459351, "train/wp.d2_loss": 0.961881697177887, "train/wp.d3_loss": 0.9590798020362854, "train/wp.d4_loss": 0.9426838159561157, "train/wp.d5_loss": 0.9488421678543091, "train/wp": 0.9488421678543091, "train/attnmap_loss": 1.3337687253952026, "train/loss": 27.135618209838867, "train/grad_norm": 14.937938690185547, "learning_rate": 7.413333333333332e-05, "momentum": 0.9, "_runtime": 121.67519903182983, "_timestamp": 1676689784.482304, "_step": 29}
{"train/det_cls.d0_loss": 0.5638538599014282, "train/det_cls.d1_loss": 0.5939411520957947, "train/det_cls.d2_loss": 0.6067259311676025, "train/det_cls.d3_loss": 0.6175708174705505, "train/det_cls.d4_loss": 0.6177846789360046, "train/det_cls.d5_loss": 0.6118406057357788, "train/det_reg.d0_loss": 2.9005379676818848, "train/det_reg.d1_loss": 2.7510266304016113, "train/det_reg.d2_loss": 2.643256425857544, "train/det_reg.d3_loss": 2.5873847007751465, "train/det_reg.d4_loss": 2.63846492767334, "train/det_reg.d5_loss": 2.630155086517334, "train/wp.d0_loss": 0.8319244384765625, "train/wp.d1_loss": 0.8265600800514221, "train/wp.d2_loss": 0.8299635052680969, "train/wp.d3_loss": 0.8305555582046509, "train/wp.d4_loss": 0.8241980671882629, "train/wp.d5_loss": 0.8168022632598877, "train/wp": 0.8168022632598877, "train/attnmap_loss": 1.411081075668335, "train/loss": 26.133628845214844, "train/grad_norm": 17.28711700439453, "learning_rate": 7.44e-05, "momentum": 0.9, "_runtime": 124.9992470741272, "_timestamp": 1676689787.8063521, "_step": 30}
{"train/det_cls.d0_loss": 0.5594122409820557, "train/det_cls.d1_loss": 0.6016755104064941, "train/det_cls.d2_loss": 0.6011958122253418, "train/det_cls.d3_loss": 0.6138458251953125, "train/det_cls.d4_loss": 0.6122751832008362, "train/det_cls.d5_loss": 0.6102929711341858, "train/det_reg.d0_loss": 2.8871116638183594, "train/det_reg.d1_loss": 2.7172279357910156, "train/det_reg.d2_loss": 2.692767858505249, "train/det_reg.d3_loss": 2.644744873046875, "train/det_reg.d4_loss": 2.6296908855438232, "train/det_reg.d5_loss": 2.6124510765075684, "train/wp.d0_loss": 0.8894428014755249, "train/wp.d1_loss": 0.8698837161064148, "train/wp.d2_loss": 0.8587709665298462, "train/wp.d3_loss": 0.8682066202163696, "train/wp.d4_loss": 0.8733490705490112, "train/wp.d5_loss": 0.8710387945175171, "train/wp": 0.8710387945175171, "train/attnmap_loss": 1.2077572345733643, "train/loss": 26.22114372253418, "train/grad_norm": 19.379793167114258, "learning_rate": 7.466666666666666e-05, "momentum": 0.9, "_runtime": 127.86614966392517, "_timestamp": 1676689790.6732547, "_step": 31}
{"train/det_cls.d0_loss": 0.5544894337654114, "train/det_cls.d1_loss": 0.6034243106842041, "train/det_cls.d2_loss": 0.6022641062736511, "train/det_cls.d3_loss": 0.6150587201118469, "train/det_cls.d4_loss": 0.609940230846405, "train/det_cls.d5_loss": 0.6085858941078186, "train/det_reg.d0_loss": 2.8880767822265625, "train/det_reg.d1_loss": 2.7073493003845215, "train/det_reg.d2_loss": 2.6688308715820312, "train/det_reg.d3_loss": 2.5959441661834717, "train/det_reg.d4_loss": 2.625925064086914, "train/det_reg.d5_loss": 2.6977767944335938, "train/wp.d0_loss": 1.0481445789337158, "train/wp.d1_loss": 1.0385713577270508, "train/wp.d2_loss": 1.0416792631149292, "train/wp.d3_loss": 1.022855520248413, "train/wp.d4_loss": 1.0237053632736206, "train/wp.d5_loss": 1.0305155515670776, "train/wp": 1.0305155515670776, "train/attnmap_loss": 1.646802544593811, "train/loss": 27.629941940307617, "train/grad_norm": 42.350852966308594, "learning_rate": 7.493333333333332e-05, "momentum": 0.9, "_runtime": 130.8848090171814, "_timestamp": 1676689793.691914, "_step": 32}
{"train/det_cls.d0_loss": 0.5700672268867493, "train/det_cls.d1_loss": 0.6148211359977722, "train/det_cls.d2_loss": 0.6141873598098755, "train/det_cls.d3_loss": 0.6236488819122314, "train/det_cls.d4_loss": 0.6245403289794922, "train/det_cls.d5_loss": 0.6219104528427124, "train/det_reg.d0_loss": 2.800422191619873, "train/det_reg.d1_loss": 2.659575939178467, "train/det_reg.d2_loss": 2.609382152557373, "train/det_reg.d3_loss": 2.5028297901153564, "train/det_reg.d4_loss": 2.558587074279785, "train/det_reg.d5_loss": 2.682980537414551, "train/wp.d0_loss": 0.9304182529449463, "train/wp.d1_loss": 0.9136939644813538, "train/wp.d2_loss": 0.9085705280303955, "train/wp.d3_loss": 0.9344190955162048, "train/wp.d4_loss": 0.93622887134552, "train/wp.d5_loss": 0.9352197647094727, "train/wp": 0.9352197647094727, "train/attnmap_loss": 2.052630662918091, "train/loss": 27.094133377075195, "train/grad_norm": 17.556110382080078, "learning_rate": 7.52e-05, "momentum": 0.9, "_runtime": 134.29785060882568, "_timestamp": 1676689797.1049557, "_step": 33}
{"train/det_cls.d0_loss": 0.5586421489715576, "train/det_cls.d1_loss": 0.5937680006027222, "train/det_cls.d2_loss": 0.5945031046867371, "train/det_cls.d3_loss": 0.6124532222747803, "train/det_cls.d4_loss": 0.6080422401428223, "train/det_cls.d5_loss": 0.6090593934059143, "train/det_reg.d0_loss": 2.862058162689209, "train/det_reg.d1_loss": 2.724123954772949, "train/det_reg.d2_loss": 2.6337838172912598, "train/det_reg.d3_loss": 2.5639939308166504, "train/det_reg.d4_loss": 2.616342067718506, "train/det_reg.d5_loss": 2.7635183334350586, "train/wp.d0_loss": 0.8719490766525269, "train/wp.d1_loss": 0.8520504236221313, "train/wp.d2_loss": 0.8672694563865662, "train/wp.d3_loss": 0.8697104454040527, "train/wp.d4_loss": 0.8720494508743286, "train/wp.d5_loss": 0.8717281818389893, "train/wp": 0.8717281818389893, "train/attnmap_loss": 1.5225303173065186, "train/loss": 26.467575073242188, "train/grad_norm": 18.869728088378906, "learning_rate": 7.546666666666667e-05, "momentum": 0.9, "_runtime": 137.67632937431335, "_timestamp": 1676689800.4834344, "_step": 34}
{"train/det_cls.d0_loss": 0.5293055772781372, "train/det_cls.d1_loss": 0.5712159276008606, "train/det_cls.d2_loss": 0.5770283937454224, "train/det_cls.d3_loss": 0.6087312698364258, "train/det_cls.d4_loss": 0.5965380668640137, "train/det_cls.d5_loss": 0.5918131470680237, "train/det_reg.d0_loss": 2.8099238872528076, "train/det_reg.d1_loss": 2.714108467102051, "train/det_reg.d2_loss": 2.635037422180176, "train/det_reg.d3_loss": 2.5502047538757324, "train/det_reg.d4_loss": 2.656930685043335, "train/det_reg.d5_loss": 2.8079068660736084, "train/wp.d0_loss": 0.9932477474212646, "train/wp.d1_loss": 0.9784252643585205, "train/wp.d2_loss": 0.9544848799705505, "train/wp.d3_loss": 0.9398787617683411, "train/wp.d4_loss": 0.9521756172180176, "train/wp.d5_loss": 0.981728196144104, "train/wp": 0.981728196144104, "train/attnmap_loss": 1.3153016567230225, "train/loss": 26.76398468017578, "train/grad_norm": 15.841930389404297, "learning_rate": 7.573333333333332e-05, "momentum": 0.9, "_runtime": 140.53516292572021, "_timestamp": 1676689803.342268, "_step": 35}
{"train/det_cls.d0_loss": 0.5345532894134521, "train/det_cls.d1_loss": 0.5815559029579163, "train/det_cls.d2_loss": 0.593125581741333, "train/det_cls.d3_loss": 0.6171385645866394, "train/det_cls.d4_loss": 0.6060075759887695, "train/det_cls.d5_loss": 0.6024509072303772, "train/det_reg.d0_loss": 2.8187456130981445, "train/det_reg.d1_loss": 2.6597604751586914, "train/det_reg.d2_loss": 2.573397636413574, "train/det_reg.d3_loss": 2.531116485595703, "train/det_reg.d4_loss": 2.6590187549591064, "train/det_reg.d5_loss": 2.7386555671691895, "train/wp.d0_loss": 0.9699790477752686, "train/wp.d1_loss": 0.9660722017288208, "train/wp.d2_loss": 0.961823582649231, "train/wp.d3_loss": 0.9597745537757874, "train/wp.d4_loss": 0.9576452970504761, "train/wp.d5_loss": 0.9660199880599976, "train/wp": 0.9660199880599976, "train/attnmap_loss": 1.4831204414367676, "train/loss": 26.77996253967285, "train/grad_norm": 16.793672561645508, "learning_rate": 7.6e-05, "momentum": 0.9, "_runtime": 143.56196403503418, "_timestamp": 1676689806.369069, "_step": 36}
{"train/det_cls.d0_loss": 0.5319954752922058, "train/det_cls.d1_loss": 0.5835217237472534, "train/det_cls.d2_loss": 0.5828367471694946, "train/det_cls.d3_loss": 0.6076722145080566, "train/det_cls.d4_loss": 0.5998567938804626, "train/det_cls.d5_loss": 0.5927728414535522, "train/det_reg.d0_loss": 2.781301498413086, "train/det_reg.d1_loss": 2.6362059116363525, "train/det_reg.d2_loss": 2.555147171020508, "train/det_reg.d3_loss": 2.552943468093872, "train/det_reg.d4_loss": 2.6590805053710938, "train/det_reg.d5_loss": 2.726130962371826, "train/wp.d0_loss": 1.0677638053894043, "train/wp.d1_loss": 1.0563833713531494, "train/wp.d2_loss": 1.0479745864868164, "train/wp.d3_loss": 1.0501258373260498, "train/wp.d4_loss": 1.0549631118774414, "train/wp.d5_loss": 1.0506795644760132, "train/wp": 1.0506795644760132, "train/attnmap_loss": 2.0654373168945312, "train/loss": 27.802793502807617, "train/grad_norm": 17.787656784057617, "learning_rate": 7.626666666666665e-05, "momentum": 0.9, "_runtime": 146.9616630077362, "_timestamp": 1676689809.768768, "_step": 37}
{"train/det_cls.d0_loss": 0.526732325553894, "train/det_cls.d1_loss": 0.5788386464118958, "train/det_cls.d2_loss": 0.5812832713127136, "train/det_cls.d3_loss": 0.6058022379875183, "train/det_cls.d4_loss": 0.5930771827697754, "train/det_cls.d5_loss": 0.5863648056983948, "train/det_reg.d0_loss": 2.837907075881958, "train/det_reg.d1_loss": 2.6817541122436523, "train/det_reg.d2_loss": 2.602825164794922, "train/det_reg.d3_loss": 2.5662777423858643, "train/det_reg.d4_loss": 2.644627332687378, "train/det_reg.d5_loss": 2.65553617477417, "train/wp.d0_loss": 0.9087775349617004, "train/wp.d1_loss": 0.8998991847038269, "train/wp.d2_loss": 0.89711594581604, "train/wp.d3_loss": 0.8965963125228882, "train/wp.d4_loss": 0.9016231894493103, "train/wp.d5_loss": 0.9000135660171509, "train/wp": 0.9000135660171509, "train/attnmap_loss": 1.9597837924957275, "train/loss": 26.82483673095703, "train/grad_norm": 18.410804748535156, "learning_rate": 7.653333333333333e-05, "momentum": 0.9, "_runtime": 150.22768378257751, "_timestamp": 1676689813.0347888, "_step": 38}
{"train/det_cls.d0_loss": 0.5292597413063049, "train/det_cls.d1_loss": 0.5828516483306885, "train/det_cls.d2_loss": 0.5774007439613342, "train/det_cls.d3_loss": 0.5955810546875, "train/det_cls.d4_loss": 0.592256486415863, "train/det_cls.d5_loss": 0.5915803909301758, "train/det_reg.d0_loss": 2.761934518814087, "train/det_reg.d1_loss": 2.613919258117676, "train/det_reg.d2_loss": 2.5320680141448975, "train/det_reg.d3_loss": 2.5040369033813477, "train/det_reg.d4_loss": 2.5186116695404053, "train/det_reg.d5_loss": 2.4677445888519287, "train/wp.d0_loss": 0.863257646560669, "train/wp.d1_loss": 0.8635824918746948, "train/wp.d2_loss": 0.8743312954902649, "train/wp.d3_loss": 0.8670768141746521, "train/wp.d4_loss": 0.8624210357666016, "train/wp.d5_loss": 0.8646364212036133, "train/wp": 0.8646364212036133, "train/attnmap_loss": 1.1943323612213135, "train/loss": 25.256881713867188, "train/grad_norm": 13.976216316223145, "learning_rate": 7.679999999999998e-05, "momentum": 0.9, "_runtime": 153.05520796775818, "_timestamp": 1676689815.862313, "_step": 39}
{"train/det_cls.d0_loss": 0.5197466611862183, "train/det_cls.d1_loss": 0.5747796893119812, "train/det_cls.d2_loss": 0.5776627063751221, "train/det_cls.d3_loss": 0.5938572883605957, "train/det_cls.d4_loss": 0.5913314819335938, "train/det_cls.d5_loss": 0.5928354859352112, "train/det_reg.d0_loss": 2.842503070831299, "train/det_reg.d1_loss": 2.6715657711029053, "train/det_reg.d2_loss": 2.613172769546509, "train/det_reg.d3_loss": 2.604470729827881, "train/det_reg.d4_loss": 2.5972557067871094, "train/det_reg.d5_loss": 2.536766529083252, "train/wp.d0_loss": 0.9579746723175049, "train/wp.d1_loss": 0.9597187042236328, "train/wp.d2_loss": 0.9478775858879089, "train/wp.d3_loss": 0.9312708377838135, "train/wp.d4_loss": 0.9316032528877258, "train/wp.d5_loss": 0.9309512376785278, "train/wp": 0.9309512376785278, "train/attnmap_loss": 1.5848441123962402, "train/loss": 26.56018829345703, "train/grad_norm": 13.039650917053223, "learning_rate": 7.706666666666664e-05, "momentum": 0.9, "_runtime": 156.0367238521576, "_timestamp": 1676689818.843829, "_step": 40}
{"train/det_cls.d0_loss": 0.5361999273300171, "train/det_cls.d1_loss": 0.5790901780128479, "train/det_cls.d2_loss": 0.580464243888855, "train/det_cls.d3_loss": 0.6003195643424988, "train/det_cls.d4_loss": 0.597975492477417, "train/det_cls.d5_loss": 0.5997623801231384, "train/det_reg.d0_loss": 2.748711585998535, "train/det_reg.d1_loss": 2.565453052520752, "train/det_reg.d2_loss": 2.5760879516601562, "train/det_reg.d3_loss": 2.483391284942627, "train/det_reg.d4_loss": 2.4669299125671387, "train/det_reg.d5_loss": 2.462869167327881, "train/wp.d0_loss": 0.9168647527694702, "train/wp.d1_loss": 0.9036500453948975, "train/wp.d2_loss": 0.9145478010177612, "train/wp.d3_loss": 0.9048733711242676, "train/wp.d4_loss": 0.8904283046722412, "train/wp.d5_loss": 0.8972049951553345, "train/wp": 0.8972049951553345, "train/attnmap_loss": 1.2558667659759521, "train/loss": 25.480690002441406, "train/grad_norm": 24.07278060913086, "learning_rate": 7.733333333333332e-05, "momentum": 0.9, "_runtime": 159.3699595928192, "_timestamp": 1676689822.1770647, "_step": 41}
{"train/det_cls.d0_loss": 0.547046959400177, "train/det_cls.d1_loss": 0.5941362380981445, "train/det_cls.d2_loss": 0.5903564095497131, "train/det_cls.d3_loss": 0.6072444319725037, "train/det_cls.d4_loss": 0.6097167134284973, "train/det_cls.d5_loss": 0.6196515560150146, "train/det_reg.d0_loss": 2.7369797229766846, "train/det_reg.d1_loss": 2.5122554302215576, "train/det_reg.d2_loss": 2.496101140975952, "train/det_reg.d3_loss": 2.4398555755615234, "train/det_reg.d4_loss": 2.419680118560791, "train/det_reg.d5_loss": 2.547632932662964, "train/wp.d0_loss": 0.9202562570571899, "train/wp.d1_loss": 0.9101836681365967, "train/wp.d2_loss": 0.9151023626327515, "train/wp.d3_loss": 0.9332185983657837, "train/wp.d4_loss": 0.9197282195091248, "train/wp.d5_loss": 0.9327512383460999, "train/wp": 0.9327512383460999, "train/attnmap_loss": 1.4373914003372192, "train/loss": 25.689287185668945, "train/grad_norm": 26.152894973754883, "learning_rate": 7.759999999999999e-05, "momentum": 0.9, "_runtime": 162.6274857521057, "_timestamp": 1676689825.4345908, "_step": 42}
{"train/det_cls.d0_loss": 0.5166438817977905, "train/det_cls.d1_loss": 0.5592281818389893, "train/det_cls.d2_loss": 0.5651406049728394, "train/det_cls.d3_loss": 0.5833027362823486, "train/det_cls.d4_loss": 0.5843666195869446, "train/det_cls.d5_loss": 0.5946488380432129, "train/det_reg.d0_loss": 2.706423759460449, "train/det_reg.d1_loss": 2.535057783126831, "train/det_reg.d2_loss": 2.497563123703003, "train/det_reg.d3_loss": 2.4245004653930664, "train/det_reg.d4_loss": 2.448603868484497, "train/det_reg.d5_loss": 2.6220686435699463, "train/wp.d0_loss": 0.9573012590408325, "train/wp.d1_loss": 0.9272041916847229, "train/wp.d2_loss": 0.9169909358024597, "train/wp.d3_loss": 0.9433578252792358, "train/wp.d4_loss": 0.936066210269928, "train/wp.d5_loss": 0.9409259557723999, "train/wp": 0.9409259557723999, "train/attnmap_loss": 1.314474105834961, "train/loss": 25.573867797851562, "train/grad_norm": 19.89841651916504, "learning_rate": 7.786666666666664e-05, "momentum": 0.9, "_runtime": 165.46403217315674, "_timestamp": 1676689828.2711372, "_step": 43}
{"train/det_cls.d0_loss": 0.5108519792556763, "train/det_cls.d1_loss": 0.5584063529968262, "train/det_cls.d2_loss": 0.5651017427444458, "train/det_cls.d3_loss": 0.5813819169998169, "train/det_cls.d4_loss": 0.5864478945732117, "train/det_cls.d5_loss": 0.5959237217903137, "train/det_reg.d0_loss": 2.7582130432128906, "train/det_reg.d1_loss": 2.598289966583252, "train/det_reg.d2_loss": 2.568995714187622, "train/det_reg.d3_loss": 2.4908792972564697, "train/det_reg.d4_loss": 2.517353057861328, "train/det_reg.d5_loss": 2.718559741973877, "train/wp.d0_loss": 0.8960021734237671, "train/wp.d1_loss": 0.8828348517417908, "train/wp.d2_loss": 0.8933462500572205, "train/wp.d3_loss": 0.8882079124450684, "train/wp.d4_loss": 0.8882060050964355, "train/wp.d5_loss": 0.8861532211303711, "train/wp": 0.8861532211303711, "train/attnmap_loss": 1.355459451675415, "train/loss": 25.740612030029297, "train/grad_norm": 18.540029525756836, "learning_rate": 7.813333333333333e-05, "momentum": 0.9, "_runtime": 168.45513319969177, "_timestamp": 1676689831.2622383, "_step": 44}
{"train/det_cls.d0_loss": 0.5279122591018677, "train/det_cls.d1_loss": 0.5687644481658936, "train/det_cls.d2_loss": 0.5786465406417847, "train/det_cls.d3_loss": 0.6091709136962891, "train/det_cls.d4_loss": 0.6089112758636475, "train/det_cls.d5_loss": 0.6155425310134888, "train/det_reg.d0_loss": 2.7678542137145996, "train/det_reg.d1_loss": 2.589569091796875, "train/det_reg.d2_loss": 2.548865556716919, "train/det_reg.d3_loss": 2.4589037895202637, "train/det_reg.d4_loss": 2.5480432510375977, "train/det_reg.d5_loss": 2.727222204208374, "train/wp.d0_loss": 0.9937772154808044, "train/wp.d1_loss": 0.9772939682006836, "train/wp.d2_loss": 0.9887625575065613, "train/wp.d3_loss": 0.9785028100013733, "train/wp.d4_loss": 0.9702847003936768, "train/wp.d5_loss": 0.9761807322502136, "train/wp": 0.9761807322502136, "train/attnmap_loss": 2.1013033390045166, "train/loss": 27.135509490966797, "train/grad_norm": 24.218975067138672, "learning_rate": 7.839999999999998e-05, "momentum": 0.9, "_runtime": 171.88135862350464, "_timestamp": 1676689834.6884637, "_step": 45}
{"train/det_cls.d0_loss": 0.5228428840637207, "train/det_cls.d1_loss": 0.5584028959274292, "train/det_cls.d2_loss": 0.5711734890937805, "train/det_cls.d3_loss": 0.5979282259941101, "train/det_cls.d4_loss": 0.5962108373641968, "train/det_cls.d5_loss": 0.6037998199462891, "train/det_reg.d0_loss": 2.68277907371521, "train/det_reg.d1_loss": 2.5352163314819336, "train/det_reg.d2_loss": 2.4777026176452637, "train/det_reg.d3_loss": 2.525092840194702, "train/det_reg.d4_loss": 2.6165215969085693, "train/det_reg.d5_loss": 2.7152183055877686, "train/wp.d0_loss": 0.8689177632331848, "train/wp.d1_loss": 0.8515099287033081, "train/wp.d2_loss": 0.8670806288719177, "train/wp.d3_loss": 0.858518123626709, "train/wp.d4_loss": 0.8523520827293396, "train/wp.d5_loss": 0.8524781465530396, "train/wp": 0.8524781465530396, "train/attnmap_loss": 1.7706618309020996, "train/loss": 25.924407958984375, "train/grad_norm": 21.01442527770996, "learning_rate": 7.866666666666665e-05, "momentum": 0.9, "_runtime": 175.17837834358215, "_timestamp": 1676689837.9854834, "_step": 46}
